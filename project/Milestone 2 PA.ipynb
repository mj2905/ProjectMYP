{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Books versus eBooks : The customer's choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to have the metadata.json and the two 5-core files reviews_Books_5.json and reviews_Kindle_Store_5.json at the same level as the notebook.\n",
    "\n",
    "For the questions asked for Milestone 2, please refer to the README file, where you will see a part dedicated to milestone 2. In this Notebook, we don't answer specifically to these questions, but we speak at each step what we technically made and failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warning :\n",
    "There are several booleans in this cell. They are useful to indicate if we need to perform some key data filtering and transformation in the whole notebook. The first one is set to True as it creates a file that is bigger than 300Mo, so that we can't put it in github. You will have to compute it if you run the notebook (it takes some time). The other files are on github, so all other booleans are set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata_path = 'metadata.json'\n",
    "books_metadata_path = 'books_metadata_with_bracket.csv'\n",
    "ebooks_metadata_title_path = 'ebooks_metadata_title.csv'\n",
    "ebooks_asin = 'ebooks_asin.csv'\n",
    "books_5core_path = 'reviews_Books_5.json'\n",
    "kindle_5core_path = 'reviews_Kindle_Store_5.json'\n",
    "amazon_ebooks = 'ebooks_title_from_amazon_complete.csv'\n",
    "amazon_aws_ebooks = 'ebooks_metadata_amazon.csv'\n",
    "amazon_aws_ebooks_undefined = 'ebooks_metadata_amazon_undefined.csv'\n",
    "amazon_aws_ebooks_log = 'ebooks_metadata_amazon_log.csv'\n",
    "asindb_ebooks = 'ebooks_title_from_asindb.csv'\n",
    "\n",
    "amazon_aws_books = 'books_metadata_amazon_p.csv'\n",
    "amazon_aws_books_undefined = 'books_metadata_amazon_undefined_p.csv'\n",
    "amazon_aws_books_log = 'books_metadata_amazon_log_p.csv'\n",
    "\n",
    "matched_books_path = 'matched_books_by_authors.csv'\n",
    "matched_ebooks_path = 'matched_ebooks_by_authors.csv'\n",
    "matched_books_short = 'matched_books.csv'\n",
    "matched_ebooks_short = 'matched_ebooks.csv'\n",
    "weighted_scores_books_path = 'weighted_scores_books.csv'\n",
    "weighted_scores_ebooks_path = 'weighted_scores_ebooks.csv'\n",
    "\n",
    "\n",
    "WRITE_BOOKS_METADATA = False\n",
    "WRITE_EBOOKS_METADATA_TITLE = False\n",
    "WRITE_EBOOK_ASIN = False\n",
    "AMAZON_GET_TITLE = False\n",
    "ASINDB_GET_TITLE = False\n",
    "WRITE_FIND_MATCHED = False\n",
    "WRITE_WEIGHTED_SCORE = True\n",
    "WRITE_SCORES = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for our project, we need to obtain ebook data and book data, we chose the Amazon dataset. On this <a href='http://jmcauley.ucsd.edu/data/amazon/'>link</a>, we have downloaded the Books and Kindle Store 5-core files. However, those files contain reviews, so that we have no information about the article title or price.\n",
    "For that reason, we had to use the metadata file, acting as an intermediate table (relationship).\n",
    "\n",
    "We obtained the metadata.json file from the cluster, as it was not available in the website.\n",
    "We accessed the cluster using ssh@iccluster060.iccluster.epfl.ch, then using \n",
    "```shell\n",
    "hadoop fs -get /datasets/productGraph/metadata.json /buffer\n",
    "```\n",
    "to move the dataset to a folder we could connect to with SCP to download it on our computer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a json file, that is not readable using the pandas read_json method. We had to use the Code part from <a href='http://jmcauley.ucsd.edu/data/amazon/'>here</a> to read it. We can see a way to read the file (a limited portion of it) below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imUrl</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>related</th>\n",
       "      <th>price</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51MKP0T4...</td>\n",
       "      <td>{'Books': 6334800}</td>\n",
       "      <td>0001048791</td>\n",
       "      <td>The Crucible: Performed by Stuart Pankin, Jero...</td>\n",
       "      <td>[[Books]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://g-ecx.images-amazon.com/images/G/01/x-s...</td>\n",
       "      <td>{'Movies &amp; TV': 376041}</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>Everyday Italian (with Giada de Laurentiis), V...</td>\n",
       "      <td>[[Movies &amp; TV, Movies]]</td>\n",
       "      <td>{'buy_after_viewing': ['B0036FO6SI', 'B000KL8O...</td>\n",
       "      <td>12.99</td>\n",
       "      <td>3Pack DVD set - Italian Classics, Parties and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               imUrl                salesRank  \\\n",
       "0  http://ecx.images-amazon.com/images/I/51MKP0T4...       {'Books': 6334800}   \n",
       "1  http://g-ecx.images-amazon.com/images/G/01/x-s...  {'Movies & TV': 376041}   \n",
       "\n",
       "         asin                                              title  \\\n",
       "0  0001048791  The Crucible: Performed by Stuart Pankin, Jero...   \n",
       "1  0000143561  Everyday Italian (with Giada de Laurentiis), V...   \n",
       "\n",
       "                categories                                            related  \\\n",
       "0                [[Books]]                                                NaN   \n",
       "1  [[Movies & TV, Movies]]  {'buy_after_viewing': ['B0036FO6SI', 'B000KL8O...   \n",
       "\n",
       "   price                                        description  \n",
       "0    NaN                                                NaN  \n",
       "1  12.99  3Pack DVD set - Italian Classics, Parties and ...  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_json(path, limit = 2): \n",
    "    g = open(path, 'r') \n",
    "    df = {}\n",
    "    for i, l in enumerate(g): \n",
    "        if i < limit:\n",
    "            df[i] = eval(l)\n",
    "        else:\n",
    "            break\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "def read_csv(path, limit = 2): \n",
    "    return pd.read_csv(path, nrows=limit)\n",
    "            \n",
    "read_json(metadata_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this metadata.json file takes more than 10 Go, for 9430088 entries (obtained by doing a wc -l metadata.json), so it does not fit in memory. Thus, as we will do a lot of tests later, we wanted to create a subfile containing only the Books metadata (we don't need video games metadata for example), with a subset of columns. We also want to write it in the csv format, to manipulate it in an easier way later.\n",
    "\n",
    "We use the regex \"\\[\\'books\" in an ignore case mode, to obtain only entries that have a category tag beginning with [Books. In fact, if we want to use the regex 'book', some entries like 0078800242 or B00000078S are not books at all, even if there is Books in the title or the category tag. The '[' is useful here to avoir this behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_book_metadata(path, regex): \n",
    "    g = open(path, 'r') \n",
    "    for l in g: \n",
    "        book = regex.search(l)\n",
    "        if book:\n",
    "            yield eval(l) \n",
    "            \n",
    "def write_df_books_metadata(from_, to, regex, columns_to_keep): \n",
    "    i = 0 \n",
    "    df = {} \n",
    "    for d in read_book_metadata(from_, regex): \n",
    "        df[i] = d \n",
    "        i += 1 \n",
    "        if i % 10000 == 0: # Here, we choose to write everything every 10'000 book entries, and clear the dataframe to free memory.\n",
    "            pd.DataFrame.from_dict(df, orient='index')[columns_to_keep].to_csv(to, header=False,mode='a')\n",
    "            df = {}\n",
    "\n",
    "COLUMNS_TO_KEEP = ['asin', 'salesRank', 'categories', 'title', 'price']\n",
    "regex = re.compile('\\[\\'books', re.IGNORECASE)\n",
    "\n",
    "if WRITE_BOOKS_METADATA:\n",
    "    pd.DataFrame(columns=[COLUMNS_TO_KEEP]).to_csv(books_metadata_path)\n",
    "    write_df_books_metadata(metadata_path, books_metadata_path, regex, COLUMNS_TO_KEEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we read what we just wrote :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1048791</td>\n",
       "      <td>{'Books': 6334800}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Crucible: Performed by Stuart Pankin, Jero...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1048775</td>\n",
       "      <td>{'Books': 13243226}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Measure for Measure: Complete &amp;amp; Unabridged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     asin            salesRank   categories  \\\n",
       "0           0  1048791   {'Books': 6334800}  [['Books']]   \n",
       "1           1  1048775  {'Books': 13243226}  [['Books']]   \n",
       "\n",
       "                                               title  price  \n",
       "0  The Crucible: Performed by Stuart Pankin, Jero...    NaN  \n",
       "1     Measure for Measure: Complete &amp; Unabridged    NaN  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_csv(books_metadata_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wanted to obtain the ebooks titles, price etc..\n",
    "For the category filter, we have to use the same trick as for the Books one : \"\\[\\'Kindle\". Please note that some book metadatas above are in fact kindle store metadatas, because the category can contain both. However, it's not a big deal if we want to do the merge later, because as we will see, pretty much no ebook has a title in the given metadata.\n",
    "\n",
    "However, for the metadatas for ebooks, there was a problem at that step :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_ebook_metadata(path, regex): \n",
    "    g = open(path, 'r') \n",
    "    for l in g: \n",
    "        ebook = regex.search(l)\n",
    "        if ebook:\n",
    "            yield eval(l) \n",
    "def obtain_df_ebooks_metadata(from_, to, regex): \n",
    "    i = 0 \n",
    "    df = {} \n",
    "    count = 0\n",
    "    for d in read_ebook_metadata(from_, regex): \n",
    "        count += 1\n",
    "        if(d.get('title')):\n",
    "            df[i] = {'asin': d.get('asin'), 'title': d.get('title')}\n",
    "            i += 1 \n",
    "    pd.DataFrame.from_dict(df, orient='index').to_csv(to)\n",
    "    print('Total ebooks in metadatas:', count)\n",
    "\n",
    "\n",
    "regex = re.compile('\\[\\'Kindle', re.IGNORECASE)\n",
    "\n",
    "if WRITE_EBOOKS_METADATA_TITLE:\n",
    "    obtain_df_ebooks_metadata(metadata_path, ebooks_metadata_title_path, regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see right below that 44 entries out of 434702 have a title. Of course, it's not good at all, since we want to merge books and ebooks using the title field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_csv(ebooks_metadata_title_path, None).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we need to obtain the title field from another source. The first idea was to retrieve this information from Amazon directly, as we wanted to do for the user location. For that, we need to have a list of the ebooks asin (Amazon Standard Identification Numbers). We obtain it from the Kindle Store 5-core file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_ebook_5core(path, regex): \n",
    "    g = open(path, 'r') \n",
    "    for l in g: \n",
    "        yield eval(l) \n",
    "def write_ebook_asin(from_, to): \n",
    "    i = 0 \n",
    "    df = {} \n",
    "    for d in read_ebook_5core(from_, regex): \n",
    "        df[i] = d \n",
    "        i += 1 \n",
    "        if i % 10000 == 0:\n",
    "            if i % 100000 == 0:\n",
    "                print(i) #to show the progression\n",
    "            pd.DataFrame.from_dict(df, orient='index')[['asin']].to_csv(to, header=False,mode='a')\n",
    "            df = {}\n",
    "    pd.DataFrame.from_dict(df, orient='index')[['asin']].to_csv(to, header=False,mode='a')\n",
    "    df = {}\n",
    "\n",
    "if WRITE_EBOOK_ASIN:\n",
    "    pd.DataFrame(columns=[['asin']]).to_csv(ebooks_asin)\n",
    "    write_ebook_asin(kindle_5core_path, ebooks_asin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we were using the Kindle Store 5-core file, there are asin duplicates. We thus make it unique when we read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B000F83SZQ', 'B000FA64PA', 'B000FA64PK', ..., 'B00M029T4O',\n",
       "       'B00M0RE7CS', 'B00M13FNSS'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebooks_asin_unique = pd.read_csv('ebooks_asin.csv',usecols=[1]).asin.unique()\n",
    "ebooks_asin_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every Amazon article with asin *xasinx*, the corresponding web page is https://www.amazon.com/dp/*xasinx*/ref=rdr_kindle_ext_tmb.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = 'https://www.amazon.com/dp/'\n",
    "suffix = '/ref=rdr_kindle_ext_tmb'\n",
    "\n",
    "USER_AGENT_CHOICES = [\n",
    "    'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:23.0) Gecko/20100101 Firefox/23.0',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.62 Safari/537.36',\n",
    "    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident/6.0)',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.146 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.146 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20140205 Firefox/24.0 Iceweasel/24.3.0',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; WOW64; rv:28.0) Gecko/20100101 Firefox/28.0',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; WOW64; rv:28.0) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to rotate the user-agent so that the bot is less likely to be considered as one. This is why we have a User-Agent array.\n",
    "At the beginning, this method was working quite well : we had obtained 503 tuples (title, category, page number, language) over 1000 requests, which could mean that we had solved the problem. However, when looking at the distribution of the 503 tuples, we could see that at the beginning, everything behaves well, we obtain most of the entries (the other ones being like the B000JMKU0Y one, an obsolete entry, that only has customer reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if AMAZON_GET_TITLE:\n",
    "    \n",
    "    LIMIT = 10\n",
    "    \n",
    "    undefined = 0\n",
    "    defined = 0\n",
    "    dataframe_original = pd.DataFrame(columns=[['asin', 'title', 'Category', 'PageNum', 'Language']])\n",
    "    dataframe = dataframe_original.copy()\n",
    "\n",
    "    dataframe_original.to_csv(amazon_ebooks)\n",
    "\n",
    "    for i, asin in enumerate(ebooks_asin_unique[:LIMIT]):\n",
    "\n",
    "        if i%10==0:\n",
    "            headers = {'User-Agent':USER_AGENT_CHOICES[np.random.randint(0, len(USER_AGENT_CHOICES))]}\n",
    "            if i > 0:\n",
    "                print('undefined:', undefined, '/ defined:', defined)\n",
    "                dataframe.to_csv(amazon_ebooks, header=False,mode='a')\n",
    "                dataframe = dataframe_original.copy()\n",
    "\n",
    "\n",
    "        r = requests.get(prefix + asin + suffix, headers=headers)\n",
    "        page_body = r.text\n",
    "        soup = BeautifulSoup(page_body, 'html.parser')\n",
    "        title = soup.find_all('span', id='ebooksProductTitle')\n",
    "        if(len(title) == 0):\n",
    "            undefined += 1\n",
    "        else:\n",
    "            defined += 1\n",
    "            title = title[0].text\n",
    "\n",
    "            ul = soup.find_all('ul', class_='a-unordered-list a-horizontal a-size-small')\n",
    "            if(len(ul) > 0):\n",
    "                details = ul[0].find_all('a', class_='a-link-normal a-color-tertiary')\n",
    "                if(len(details) > 0):\n",
    "                    category = details[-1].text.strip()\n",
    "                else:\n",
    "                    category = \"\"\n",
    "            else:\n",
    "                category = \"\"\n",
    "\n",
    "            details = soup.find_all('table', id='productDetailsTable')\n",
    "            if(len(details) > 0):\n",
    "                length = details[0].find_all('b', text='Print Length:')\n",
    "                if(len(length) > 0):\n",
    "                    page_number = length[0].parent.text.split()[2]\n",
    "                else:\n",
    "                    page_number = 0\n",
    "\n",
    "                length = details[0].find_all('b', text='Language:')\n",
    "                if(len(length) > 0):\n",
    "                    language = length[0].parent.text.split()[1]\n",
    "                else:\n",
    "                    language = \"\"\n",
    "            else:\n",
    "                page_number = pd.np.nan\n",
    "                language = \"\"\n",
    "\n",
    "            dataframe.loc[asin] = (asin, title, category, page_number, language)\n",
    "\n",
    "        waiting = np.random.rand()\n",
    "        time.sleep(waiting+1)\n",
    "\n",
    "    print(defined,',',undefined)\n",
    "    dataframe.to_csv(amazon_ebooks, header=False,mode='a')\n",
    "    dataframe = dataframe_original.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But after some time, we get less and less entries : a message is sent by Amazon when retrieving the page, saying that it's not a good idea to continue scraping data, and that it might be a good idea to go through their API. So, there were some options :\n",
    "- we continue to work with the bot while tweaking the parameters to behave like a normal user for the bot (by increasing the waiting time and rotating the user-agent as said before) :\n",
    "\n",
    "After some online search (https://www.scrapehero.com/how-to-prevent-getting-blacklisted-while-scraping/,\n",
    "http://blog.datahut.co/tutorial-how-to-scrape-amazon-using-python-scrapy/,\n",
    "http://docs.aws.amazon.com/AWSECommerceService/latest/DG/rest-signature.html,\n",
    "https://www.scrapehero.com/tutorial-how-to-scrape-amazon-product-details-using-python/,\n",
    "https://blog.hartleybrody.com/scrape-amazon/), we saw that Amazon was detecting the IP, it could ban it, and the solution to avoid it was to use a proxy crawler. As it costs money, we decided not to use that. Furthermore, as said here, it's a legally speaking grey area : https://benbernardblog.com/web-scraping-and-crawling-are-perfectly-legal-right/.\n",
    "\n",
    "- we try to go through the Amazon API : \n",
    "\n",
    "For the standard account, we need to put bank account information, so we prefer not to do so. For the student account, as we realized some days before the deadline that it existed, we might consider this option in the future if needed, but we wait for the epfl to accept or not the account request.\n",
    "\n",
    "- we find a field in the metadata, different from the title, that can help us to merge a book with an ebook :\n",
    "\n",
    "With some manual analysis, we found a pair of book-ebook : \n",
    "\n",
    "    {'asin': 'B000JML1QG', 'price': 0.99, 'imUrl': 'http://ecx.images-amazon.com/images/I/41VbZ%2BvxslL._BO2,204,203,200_PIsitb-sticker-v3-big,TopRight,0,-55_SX278_SY278_PIkin4,BottomRight,1,22_AA300_SH20_OU01_.jpg', 'related': {'also_viewed': ['B005LSCQ4Y', 'B0082UXYTE', 'B004TS2B4W'], 'buy_after_viewing': ['B00CS6P31U', 'B005LSCQ4Y', 'B0051EZX8Y', 'B006CRC98G']}, 'categories': [['Books', \"Children's Books\", 'Fairy Tales, Folk Tales & Myths', 'Anthologies'], ['Books', 'Literature & Fiction'], ['Kindle Store', 'Kindle eBooks', \"Children's eBooks\", 'Fairy Tales, Folk Tales & Myths', 'Anthologies'], ['Kindle Store', 'Kindle eBooks', \"Children's eBooks\", 'Fairy Tales, Folk Tales & Myths', 'Collections'], ['Kindle Store', 'Kindle eBooks', 'Literature & Fiction', 'Mythology & Folk Tales'], ['Kindle Store', 'Kindle eBooks', 'Science Fiction & Fantasy', 'Fantasy', 'Fairy Tales']]}\n",
    "\n",
    "\n",
    "    {'asin': '0554319187', 'title': \"Grimm's Fairy Stories\", 'price': 0.99, 'imUrl': 'http://ecx.images-amazon.com/images/I/41O2olixwXL.jpg', 'related': {'also_viewed': ['1607103133', '0394709306', '1937994317'], 'buy_after_viewing': ['1607103133', '0394709306', '0393088863', '0385189508']}, 'salesRank': {'Books': 2586251}, 'categories': [['Books']]}\n",
    "\n",
    "As we can see here, the only entry that is the same is the price, and it's dangerous to merge on the price as ebooks are often less expensive than the book version for the same content.\n",
    "\n",
    "- we find another service that can give us the title for a given asin :\n",
    "\n",
    "This is the option that we finally chose. The website http://asindb.com/ does exactly that. For this website, there is no bot detection as Amazon does. We can't retrieve the price, the category and the number of pages, but at least we can get the title. We can see the result below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if ASINDB_GET_TITLE:\n",
    "    \n",
    "    LIMIT = 20\n",
    "    \n",
    "    prefix_asindb = 'http://asindb.com/USA/ASIN/'\n",
    "\n",
    "    dataframe = pd.DataFrame(columns=[['asin', 'title']])\n",
    "    notdefined = pd.DataFrame(columns=[['asin','notfound']])\n",
    "    dataframe.to_csv(asindb_ebooks)\n",
    "\n",
    "    for i, asin in enumerate(ebooks_asin_unique[:LIMIT]):\n",
    "        r = requests.get(prefix_asindb + asin, headers={'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:23.0) Gecko/20100101 Firefox/23.0'})\n",
    "        page_body = r.text\n",
    "        soup = BeautifulSoup(page_body, 'html.parser')\n",
    "\n",
    "        if i%10 == 0:\n",
    "            dataframe.to_csv(asindb_ebooks, header=False,mode='a')\n",
    "            dataframe = pd.DataFrame(columns=[['asin', 'title']])\n",
    "\n",
    "        notfound = soup.find_all('h6', text = 'No item found!!!')\n",
    "        if(len(notfound) > 0):\n",
    "            notdefined.loc[asin] = (asin,1)\n",
    "        else:\n",
    "            title = soup.find_all('th', text='Title')\n",
    "            if(len(title) > 0 and len(title[0].parent.findChildren()) >= 2):\n",
    "                dataframe.loc[asin] = (asin, title[0].parent.findChildren()[1].text)\n",
    "            else:\n",
    "                print('alerte :', asin)\n",
    "\n",
    "        waiting = np.random.rand()\n",
    "        time.sleep(waiting+1)\n",
    "\n",
    "    dataframe.to_csv(asindb_ebooks, header=False,mode='a')\n",
    "    dataframe = pd.DataFrame(columns=[['asin', 'title']])\n",
    "    \n",
    "    print(notdefined.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right above is the undefined entries dataframe (see below for more explanation).\n",
    "\n",
    "We can see below what kind of output it gives to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000FA64PA</td>\n",
       "      <td>B000FA64PA</td>\n",
       "      <td>Saboteur: Star Wars Legends (Darth Maul) (Shor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000FA64PK</td>\n",
       "      <td>B000FA64PK</td>\n",
       "      <td>Recovery: Star Wars Legends (The New Jedi Orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>Ylesia: Star Wars Legends (The New Jedi Order)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000FBFMVG</td>\n",
       "      <td>B000FBFMVG</td>\n",
       "      <td>A Forest Apart: Star Wars Legends (Short Story...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000FC1BN8</td>\n",
       "      <td>B000FC1BN8</td>\n",
       "      <td>Fool's Bargain: Star Wars Legends (Novella) (S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        asin                                              title\n",
       "0  B000FA64PA  B000FA64PA  Saboteur: Star Wars Legends (Darth Maul) (Shor...\n",
       "1  B000FA64PK  B000FA64PK  Recovery: Star Wars Legends (The New Jedi Orde...\n",
       "2  B000FA64QO  B000FA64QO  Ylesia: Star Wars Legends (The New Jedi Order)...\n",
       "3  B000FBFMVG  B000FBFMVG  A Forest Apart: Star Wars Legends (Short Story...\n",
       "4  B000FC1BN8  B000FC1BN8  Fool's Bargain: Star Wars Legends (Novella) (S..."
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebooks_metadata = read_csv(asindb_ebooks, None)\n",
    "ebooks_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2741"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_csv(asindb_ebooks, None).shape[0] # number of titles retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution is of course not the best one : the asindb website does not contain everything. We have managed to retrieve 2741 titles over 4000 asins by using this technique, but we have no problem with the Amazon bot detection (and possible ban). We can see which entries were not retrieved by printing the notdefined dataframe.\n",
    "\n",
    "Of course, tu retrieve the 2741 entries, we set the LIMIT constant in the code to be 4000.\n",
    "\n",
    "We thus continue our analysis by using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as we have the title information for books and ebooks, let's merge them. We read the book metadata information in books_metadata and we have the ebook metadata information with title in ebooks_metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0001048791</td>\n",
       "      <td>{'Books': 6334800}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Crucible: Performed by Stuart Pankin, Jero...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0001048775</td>\n",
       "      <td>{'Books': 13243226}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Measure for Measure: Complete &amp;amp; Unabridged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0001048236</td>\n",
       "      <td>{'Books': 8973864}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Sherlock Holmes Audio Collection</td>\n",
       "      <td>9.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0000401048</td>\n",
       "      <td>{'Books': 6448843}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The rogue of publishers' row;: Confessions of ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001019880</td>\n",
       "      <td>{'Books': 9589258}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Classic Soul Winner's New Testament Bible</td>\n",
       "      <td>5.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        asin            salesRank   categories  \\\n",
       "0           0  0001048791   {'Books': 6334800}  [['Books']]   \n",
       "1           1  0001048775  {'Books': 13243226}  [['Books']]   \n",
       "2           2  0001048236   {'Books': 8973864}  [['Books']]   \n",
       "3           3  0000401048   {'Books': 6448843}  [['Books']]   \n",
       "4           4  0001019880   {'Books': 9589258}  [['Books']]   \n",
       "\n",
       "                                               title  price  \n",
       "0  The Crucible: Performed by Stuart Pankin, Jero...    NaN  \n",
       "1     Measure for Measure: Complete &amp; Unabridged    NaN  \n",
       "2               The Sherlock Holmes Audio Collection   9.26  \n",
       "3  The rogue of publishers' row;: Confessions of ...    NaN  \n",
       "4          Classic Soul Winner's New Testament Bible   5.39  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_metadata = pd.read_csv(books_metadata_path)\n",
    "books_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge them on title, and we see that we only get 1297 entries. It's not bad, but we can for sure have a better result. As we can remark, there is a lot of time the title The Space Between. We will discuss later about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin_books</th>\n",
       "      <th>asin_ebooks</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002008505</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>{'Books': 5587764}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Space Between</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0615891411</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>{'Books': 4145053}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Space Between</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1579660584</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>{'Books': 2486827}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Space Between</td>\n",
       "      <td>20.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1588515508</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>{'Books': 5985767}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Space Between</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1595143394</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>{'Books': 141638}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Space Between</td>\n",
       "      <td>7.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   asin_books asin_ebooks           salesRank   categories              title  \\\n",
       "0  0002008505  B002DYJ7DM  {'Books': 5587764}  [['Books']]  The Space Between   \n",
       "1  0615891411  B002DYJ7DM  {'Books': 4145053}  [['Books']]  The Space Between   \n",
       "2  1579660584  B002DYJ7DM  {'Books': 2486827}  [['Books']]  The Space Between   \n",
       "3  1588515508  B002DYJ7DM  {'Books': 5985767}  [['Books']]  The Space Between   \n",
       "4  1595143394  B002DYJ7DM   {'Books': 141638}  [['Books']]  The Space Between   \n",
       "\n",
       "   price  \n",
       "0   4.74  \n",
       "1   2.99  \n",
       "2  20.08  \n",
       "3    NaN  \n",
       "4   7.13  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We merge, and get the head. Everything after is here just to have a nicer representation of the first elements\n",
    "books_metadata.merge(ebooks_metadata, left_on='title', right_on='title').head().iloc[:,[1,7,2,3,4,5]].rename(columns={'asin_x':'asin_books', 'asin_y':'asin_ebooks'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1297"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_metadata.merge(ebooks_metadata, left_on='title', right_on='title').shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we were saying, 1297 is not a big number, and we can do better. We have done the most basic possible thing to do : we have put the title for books and ebooks in lower form (minuscule)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0001048791</td>\n",
       "      <td>{'Books': 6334800}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>the crucible: performed by stuart pankin, jero...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0001048775</td>\n",
       "      <td>{'Books': 13243226}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>measure for measure: complete &amp;amp; unabridged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0001048236</td>\n",
       "      <td>{'Books': 8973864}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>the sherlock holmes audio collection</td>\n",
       "      <td>9.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0000401048</td>\n",
       "      <td>{'Books': 6448843}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>the rogue of publishers' row;: confessions of ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001019880</td>\n",
       "      <td>{'Books': 9589258}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>classic soul winner's new testament bible</td>\n",
       "      <td>5.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        asin            salesRank   categories  \\\n",
       "0           0  0001048791   {'Books': 6334800}  [['Books']]   \n",
       "1           1  0001048775  {'Books': 13243226}  [['Books']]   \n",
       "2           2  0001048236   {'Books': 8973864}  [['Books']]   \n",
       "3           3  0000401048   {'Books': 6448843}  [['Books']]   \n",
       "4           4  0001019880   {'Books': 9589258}  [['Books']]   \n",
       "\n",
       "                                               title  price  \n",
       "0  the crucible: performed by stuart pankin, jero...    NaN  \n",
       "1     measure for measure: complete &amp; unabridged    NaN  \n",
       "2               the sherlock holmes audio collection   9.26  \n",
       "3  the rogue of publishers' row;: confessions of ...    NaN  \n",
       "4          classic soul winner's new testament bible   5.39  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_metadata['title'] = books_metadata.title.str.lower()\n",
    "books_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000FA64PA</td>\n",
       "      <td>B000FA64PA</td>\n",
       "      <td>saboteur: star wars legends (darth maul) (shor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000FA64PK</td>\n",
       "      <td>B000FA64PK</td>\n",
       "      <td>recovery: star wars legends (the new jedi orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>ylesia: star wars legends (the new jedi order)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000FBFMVG</td>\n",
       "      <td>B000FBFMVG</td>\n",
       "      <td>a forest apart: star wars legends (short story...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000FC1BN8</td>\n",
       "      <td>B000FC1BN8</td>\n",
       "      <td>fool's bargain: star wars legends (novella) (s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        asin                                              title\n",
       "0  B000FA64PA  B000FA64PA  saboteur: star wars legends (darth maul) (shor...\n",
       "1  B000FA64PK  B000FA64PK  recovery: star wars legends (the new jedi orde...\n",
       "2  B000FA64QO  B000FA64QO  ylesia: star wars legends (the new jedi order)...\n",
       "3  B000FBFMVG  B000FBFMVG  a forest apart: star wars legends (short story...\n",
       "4  B000FC1BN8  B000FC1BN8  fool's bargain: star wars legends (novella) (s..."
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebooks_metadata['title'] = ebooks_metadata.title.str.lower()\n",
    "ebooks_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_metadatas = books_metadata.merge(ebooks_metadata, left_on='title', right_on='title')\n",
    "merged_metadatas = merged_metadatas[['asin_x', 'asin_y', 'title', 'price', 'categories', 'salesRank']]\n",
    "merged_metadatas = merged_metadatas.rename(columns={'asin_x': 'asin_book', 'asin_y': 'asin_ebook'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin_book</th>\n",
       "      <th>asin_ebook</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>categories</th>\n",
       "      <th>salesRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002008505</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>the space between</td>\n",
       "      <td>4.74</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 5587764}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0615891411</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>the space between</td>\n",
       "      <td>2.99</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 4145053}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1579660584</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>the space between</td>\n",
       "      <td>20.08</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 2486827}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1588515508</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>the space between</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 5985767}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1595143394</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>the space between</td>\n",
       "      <td>7.13</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 141638}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    asin_book  asin_ebook              title  price   categories  \\\n",
       "0  0002008505  B002DYJ7DM  the space between   4.74  [['Books']]   \n",
       "1  0615891411  B002DYJ7DM  the space between   2.99  [['Books']]   \n",
       "2  1579660584  B002DYJ7DM  the space between  20.08  [['Books']]   \n",
       "3  1588515508  B002DYJ7DM  the space between    NaN  [['Books']]   \n",
       "4  1595143394  B002DYJ7DM  the space between   7.13  [['Books']]   \n",
       "\n",
       "            salesRank  \n",
       "0  {'Books': 5587764}  \n",
       "1  {'Books': 4145053}  \n",
       "2  {'Books': 2486827}  \n",
       "3  {'Books': 5985767}  \n",
       "4   {'Books': 141638}  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_metadatas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, we have a bigger number of entries. We could have tried to increase this number, however as we will see later, we already have some problems with this 'strict' way of doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1506"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_metadatas.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have merged the two dataframes into one, and it seems that we can do some analysis on it. We have 1506 entries, so it's good for a first analysis in milestone 2 to do so.\n",
    "But, as said before, there are title duplicates. It corresponds to books (there is only one duplicate entry for ebooks, for the article 'Second Chances') that have the same title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin_book</th>\n",
       "      <th>asin_ebook</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>categories</th>\n",
       "      <th>salesRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002008505</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>the space between</td>\n",
       "      <td>4.74</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 5587764}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0615891411</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>the space between</td>\n",
       "      <td>2.99</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 4145053}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1579660584</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>the space between</td>\n",
       "      <td>20.08</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 2486827}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1588515508</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>the space between</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 5985767}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1595143394</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>the space between</td>\n",
       "      <td>7.13</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 141638}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1601540817</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>the space between</td>\n",
       "      <td>10.99</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 11114107}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1625530226</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>the space between</td>\n",
       "      <td>6.99</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 2678708}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    asin_book  asin_ebook              title  price   categories  \\\n",
       "0  0002008505  B002DYJ7DM  the space between   4.74  [['Books']]   \n",
       "1  0615891411  B002DYJ7DM  the space between   2.99  [['Books']]   \n",
       "2  1579660584  B002DYJ7DM  the space between  20.08  [['Books']]   \n",
       "3  1588515508  B002DYJ7DM  the space between    NaN  [['Books']]   \n",
       "4  1595143394  B002DYJ7DM  the space between   7.13  [['Books']]   \n",
       "5  1601540817  B002DYJ7DM  the space between  10.99  [['Books']]   \n",
       "6  1625530226  B002DYJ7DM  the space between   6.99  [['Books']]   \n",
       "\n",
       "             salesRank  \n",
       "0   {'Books': 5587764}  \n",
       "1   {'Books': 4145053}  \n",
       "2   {'Books': 2486827}  \n",
       "3   {'Books': 5985767}  \n",
       "4    {'Books': 141638}  \n",
       "5  {'Books': 11114107}  \n",
       "6   {'Books': 2678708}  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_metadatas.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count               2741\n",
       "unique              2739\n",
       "top       second chances\n",
       "freq                   2\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebooks_metadata.title.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We thus thought that we could consider only pairs that have a unique title in the whole dataframe. In that way, we only have articles that have a unique name, at least in the period in which the dataset has been created, so that we could only have exactly the same content for the book and the ebook. \n",
    "\n",
    "We thus drop all elements that have a title that exists more than one time in the dataframe.\n",
    "\n",
    "It's naive, as we don't have all books and ebooks of Amazon, even for the period given, but we wanted to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin_book</th>\n",
       "      <th>asin_ebook</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>categories</th>\n",
       "      <th>salesRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0007269854</td>\n",
       "      <td>B003ZUY19I</td>\n",
       "      <td>the ice princess</td>\n",
       "      <td>7.59</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 2527081}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0060517689</td>\n",
       "      <td>B0036ZAHDG</td>\n",
       "      <td>in the mood</td>\n",
       "      <td>2.99</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 2663548}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0060595620</td>\n",
       "      <td>B00480P58K</td>\n",
       "      <td>the sweetest taboo</td>\n",
       "      <td>8.70</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 2956119}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0060813032</td>\n",
       "      <td>B0049H8X86</td>\n",
       "      <td>dragons from the sea (the strongbow saga, book 2)</td>\n",
       "      <td>3.60</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 1269204}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0061084220</td>\n",
       "      <td>B004QS98KU</td>\n",
       "      <td>raven's bride</td>\n",
       "      <td>7.69</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 2911109}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>0140249249</td>\n",
       "      <td>B003XVYGXK</td>\n",
       "      <td>iced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 1225702}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0140259678</td>\n",
       "      <td>B003C1R5CA</td>\n",
       "      <td>a timely death</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>{'Books': 3077680}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      asin_book  asin_ebook  \\\n",
       "39   0007269854  B003ZUY19I   \n",
       "95   0060517689  B0036ZAHDG   \n",
       "121  0060595620  B00480P58K   \n",
       "173  0060813032  B0049H8X86   \n",
       "200  0061084220  B004QS98KU   \n",
       "460  0140249249  B003XVYGXK   \n",
       "461  0140259678  B003C1R5CA   \n",
       "\n",
       "                                                 title  price   categories  \\\n",
       "39                                    the ice princess   7.59  [['Books']]   \n",
       "95                                         in the mood   2.99  [['Books']]   \n",
       "121                                 the sweetest taboo   8.70  [['Books']]   \n",
       "173  dragons from the sea (the strongbow saga, book 2)   3.60  [['Books']]   \n",
       "200                                      raven's bride   7.69  [['Books']]   \n",
       "460                                               iced    NaN  [['Books']]   \n",
       "461                                     a timely death    NaN  [['Books']]   \n",
       "\n",
       "              salesRank  \n",
       "39   {'Books': 2527081}  \n",
       "95   {'Books': 2663548}  \n",
       "121  {'Books': 2956119}  \n",
       "173  {'Books': 1269204}  \n",
       "200  {'Books': 2911109}  \n",
       "460  {'Books': 1225702}  \n",
       "461  {'Books': 3077680}  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_metadatas = merged_metadatas.drop_duplicates('title',keep=False)\n",
    "merged_metadatas.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now only have 148 elements in the merged collection. We reming the reader about the fact that we tried to obtain 4000 ebooks titles, we got only 2741. By merging, we got 1506 entries, and when we drop all elements that have duplicates, we only have 148 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_metadatas.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some manual analysis, we have unfortunately seen that for most entries, even if there is only one tuple (asin_book, asin_ebook), the two are not on the same content. We have an example for the first entry (the ice princess) : 'https://www.amazon.com/Princess-Patrik-Hedstrom-Erica-Falck/dp/0007269854' and 'https://www.amazon.com/Ice-Princess-Elizabeth-Hoyt-ebook/dp/B003ZUY19I' have the same title but are written by two different people, and have different content.\n",
    "\n",
    "There are some tuples that match : for the article 'dragons from the sea (the strongbow saga, book 2)', we have the same content.\n",
    "\n",
    "It's hard for us to quantify the number of such articles that do not match. We have done some by hand, and we have seen that a lot was not matching at all. A way to have good matches automatically could be to obtain the authors. We think that for the same author, it's rare to have two book with the same name. If we forget a minute about problems like the number of authors which is different for the ebook and the book even if it's the same, or different naming conventions (A fictive example : J. F. Brown or J. Brown), we would need the author information for each book and ebook of the tuples that we have merged.\n",
    "\n",
    "The website we were <a href='http://asindb.com/'>using</a> does not provide this information. We then need to obtain it from somewhere else. \n",
    "\n",
    "We have tried to look at the library genesis, using this <a href='http://garbage.world/posts/libgen/'>tutorial</a>. However, there are only two ways to get back information about a book : using a special id (Libgen id), or by date. Furthermore, the asin field exists, but after some tests for which none of the articles had asin, it's hard to say if it's a good option. Thus, we have thought it's not the best solution for us.\n",
    "\n",
    "We have also been told to look at the Gutenberg project. It could have been a good idea if we could search by asin in the metadatas, that are available. However, it seems that the asin data is not available, so we won't use it neither."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B000F83SZQ', 'B000FA64PA', 'B000FA64PK', ..., 'B00M029T4O',\n",
       "       'B00M0RE7CS', 'B00M13FNSS'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebooks_asin_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bottlenose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,AWS_ASSOCIATE_TAG) = pd.read_csv('amazon_keys.csv', header=None, usecols=[1]).values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon = bottlenose.Amazon(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_ASSOCIATE_TAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_handler(err):\n",
    "    ex = err['exception']\n",
    "    if isinstance(ex, HTTPError) and ex.code == 503:\n",
    "        time.sleep(random.expovariate(0.1))\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response = amazon.ItemLookup(ItemId=ebooks_asin_unique[0], ErrorHandler=error_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<?xml version=\"1.0\" ?>\\n<itemlookupresponse xmlns=\"http://webservices.amazon.com/AWSECommerceService/2013-08-01\">\\n <operationrequest>\\n  <httpheaders>\\n   <header name=\"UserAgent\" value=\"Python-urllib/3.6\">\\n   </header>\\n  </httpheaders>\\n  <requestid>\\n   1d8a9637-c9b6-4844-be8b-4da202f519c8\\n  </requestid>\\n  <arguments>\\n   <argument name=\"AWSAccessKeyId\" value=\"AKIAIQYRN6QJNHOGZS7Q\">\\n   </argument>\\n   <argument name=\"AssociateTag\" value=\"mj066-20\">\\n   </argument>\\n   <argument name=\"ItemId\" value=\"ebooks_asin.csv\">\\n   </argument>\\n   <argument name=\"Operation\" value=\"ItemLookup\">\\n   </argument>\\n   <argument name=\"Service\" value=\"AWSECommerceService\">\\n   </argument>\\n   <argument name=\"Timestamp\" value=\"2017-12-01T17:00:41Z\">\\n   </argument>\\n   <argument name=\"Version\" value=\"2013-08-01\">\\n   </argument>\\n   <argument name=\"Signature\" value=\"CsYCbXdYDWY+6U4fUUjyIBoPiiP53kaEaDZKovCQnHM=\">\\n   </argument>\\n  </arguments>\\n  <requestprocessingtime>\\n   0.0025390810000000\\n  </requestprocessingtime>\\n </operationrequest>\\n <items>\\n  <request>\\n   <isvalid>\\n    True\\n   </isvalid>\\n   <itemlookuprequest>\\n    <idtype>\\n     ASIN\\n    </idtype>\\n    <itemid>\\n     EBOOKS_ASIN.CSV\\n    </itemid>\\n    <responsegroup>\\n     Small\\n    </responsegroup>\\n    <variationpage>\\n     All\\n    </variationpage>\\n   </itemlookuprequest>\\n   <errors>\\n    <error>\\n     <code>\\n      AWS.InvalidParameterValue\\n     </code>\\n     <message>\\n      EBOOKS_ASIN.CSV is not a valid value for ItemId. Please change this value and retry your request.\\n     </message>\\n    </error>\\n   </errors>\\n  </request>\\n </items>\\n</itemlookupresponse>'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeautifulSoup(response, 'html.parser').prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Matter of Policy [An Amy Brewster Mystery]\n",
      "['Sam Merwin Jr.']\n",
      "PageTurner\n"
     ]
    }
   ],
   "source": [
    "authors_retrieved = []\n",
    "\n",
    "\n",
    "titles = soup.find_all('title')\n",
    "if(len(titles) != 0):\n",
    "    title_retrieved = titles[0].text.strip()\n",
    "\n",
    "manufacturers = soup.find_all('manufacturer')\n",
    "if(len(manufacturers) != 0):\n",
    "    manufacturer_retrieved = manufacturers[0].text.strip()\n",
    "\n",
    "authors = soup.find_all('author')\n",
    "if(len(authors) != 0):\n",
    "    for author in authors:\n",
    "        authors_retrieved += [author.text.strip()]\n",
    "\n",
    "print(title_retrieved)\n",
    "print(authors_retrieved)\n",
    "print(manufacturer_retrieved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "responsebis = amazon.ItemLookup(ItemId=ebooks_asin_unique[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(responsebis, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<?xml version=\"1.0\" ?>\\n<itemlookupresponse xmlns=\"http://webservices.amazon.com/AWSECommerceService/2013-08-01\">\\n <operationrequest>\\n  <httpheaders>\\n   <header name=\"UserAgent\" value=\"Python-urllib/3.6\">\\n   </header>\\n  </httpheaders>\\n  <requestid>\\n   0b0c62d4-9c03-4a4d-b13d-13ab450b97f4\\n  </requestid>\\n  <arguments>\\n   <argument name=\"AWSAccessKeyId\" value=\"AKIAIQYRN6QJNHOGZS7Q\">\\n   </argument>\\n   <argument name=\"AssociateTag\" value=\"mj066-20\">\\n   </argument>\\n   <argument name=\"ItemId\" value=\"B000FA64PA\">\\n   </argument>\\n   <argument name=\"Operation\" value=\"ItemLookup\">\\n   </argument>\\n   <argument name=\"ResponseGroup\" value=\"OfferSummary\">\\n   </argument>\\n   <argument name=\"Service\" value=\"AWSECommerceService\">\\n   </argument>\\n   <argument name=\"Timestamp\" value=\"2017-12-01T16:28:38Z\">\\n   </argument>\\n   <argument name=\"Version\" value=\"2013-08-01\">\\n   </argument>\\n   <argument name=\"Signature\" value=\"PR0S8fhlhZco3qBPwLYATLJ7ZpWlNJEY/ES+VtQXk24=\">\\n   </argument>\\n  </arguments>\\n  <requestprocessingtime>\\n   0.0184872190000000\\n  </requestprocessingtime>\\n </operationrequest>\\n <items>\\n  <request>\\n   <isvalid>\\n    True\\n   </isvalid>\\n   <itemlookuprequest>\\n    <idtype>\\n     ASIN\\n    </idtype>\\n    <itemid>\\n     B000FA64PA\\n    </itemid>\\n    <responsegroup>\\n     OfferSummary\\n    </responsegroup>\\n    <variationpage>\\n     All\\n    </variationpage>\\n   </itemlookuprequest>\\n  </request>\\n  <item>\\n   <asin>\\n    B000FA64PA\\n   </asin>\\n  </item>\\n </items>\\n</itemlookupresponse>'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.prettify()#.find('itemattributes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saboteur: Star Wars Legends (Darth Maul) (Short Story) (Star Wars: Darth Maul Book 1)\n",
      "['James Luceno', 'Ron Marz', 'Jan Duursema', 'Rick Magyar', 'Drew Struzan']\n",
      "Del Rey\n"
     ]
    }
   ],
   "source": [
    "authors_retrieved = []\n",
    "\n",
    "\n",
    "titles = soup.find_all('title')\n",
    "if(len(titles) != 0):\n",
    "    title_retrieved = titles[0].text.strip()\n",
    "\n",
    "manufacturers = soup.find_all('manufacturer')\n",
    "if(len(manufacturers) != 0):\n",
    "    manufacturer_retrieved = manufacturers[0].text.strip()\n",
    "\n",
    "authors = soup.find_all('author')\n",
    "if(len(authors) != 0):\n",
    "    for author in authors:\n",
    "        authors_retrieved += [author.text.strip()]\n",
    "\n",
    "print(title_retrieved)\n",
    "print(authors_retrieved)\n",
    "print(manufacturer_retrieved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B000F83SZQ',\n",
       " 'A Matter of Policy [An Amy Brewster Mystery]',\n",
       " ['James Luceno', 'Ron Marz', 'Jan Duursema', 'Rick Magyar', 'Drew Struzan'],\n",
       " 'PageTurner']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ebooks_asin_unique[0], title_retrieved, \n",
    "                                          ['James Luceno', 'Ron Marz', 'Jan Duursema', 'Rick Magyar', 'Drew Struzan'], manufacturer_retrieved]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B000F83SZQ</th>\n",
       "      <td>James Luceno, Ron Marz, Jan Duursema, Rick Mag...</td>\n",
       "      <td>PageTurner</td>\n",
       "      <td>A Matter of Policy [An Amy Brewster Mystery]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      authors manufacturer  \\\n",
       "B000F83SZQ  James Luceno, Ron Marz, Jan Duursema, Rick Mag...   PageTurner   \n",
       "\n",
       "                                                   title  \n",
       "B000F83SZQ  A Matter of Policy [An Amy Brewster Mystery]  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'title':title_retrieved,'authors':\", \".join(['James Luceno', 'Ron Marz', 'Jan Duursema', 'Rick Magyar', 'Drew Struzan']), 'manufacturer':manufacturer_retrieved},index=[ebooks_asin_unique[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe_ebooks = pd.DataFrame(columns=['title', 'authors', 'manufacturer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>manufacturer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B000FC2MB8</th>\n",
       "      <td>Brionne: A Novel</td>\n",
       "      <td>Louis L'Amour</td>\n",
       "      <td>Bantam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B000FDJ0FS</th>\n",
       "      <td>The Wall Street Journal</td>\n",
       "      <td></td>\n",
       "      <td>Dow Jones &amp; Company Inc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title        authors              manufacturer\n",
       "B000FC2MB8         Brionne: A Novel  Louis L'Amour                    Bantam\n",
       "B000FDJ0FS  The Wall Street Journal                 Dow Jones & Company Inc."
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_entry = pd.DataFrame({'title':title_retrieved,'authors':\", \".join(['James Luceno', 'Ron Marz', 'Jan Duursema', 'Rick Magyar', 'Drew Struzan']), 'manufacturer':manufacturer_retrieved},index=[ebooks_asin_unique[0]])\n",
    "dataframe_ebooks.append(new_entry)\n",
    "#dataframe_ebooks.append({'asin':ebooks_asin_unique[0], 'title':title_retrieved, \n",
    "#                                          'authors':authors_retrieved, 'manufacturer':manufacturer_retrieved}, ignore_index=True)\n",
    "dataframe_ebooks[['title', 'authors', 'manufacturer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe_undefined = pd.Series()\n",
    "\n",
    "dataframe_undefined.to_csv(amazon_aws_ebooks_undefined)\n",
    "\n",
    "dataframe_undefined = dataframe_undefined.append(pd.Series(ebooks_asin_unique[0]))\n",
    "dataframe_undefined = dataframe_undefined.append(pd.Series(ebooks_asin_unique[1]))\n",
    "\n",
    "dataframe_undefined.to_csv(amazon_aws_ebooks_undefined, header=False,mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>manufacturer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B000FC2MB8</th>\n",
       "      <td>Brionne: A Novel</td>\n",
       "      <td>Louis L'Amour</td>\n",
       "      <td>Bantam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B000FDJ0FS</th>\n",
       "      <td>The Wall Street Journal</td>\n",
       "      <td></td>\n",
       "      <td>Dow Jones &amp; Company Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title        authors              manufacturer\n",
       "B000FC2MB8         Brionne: A Novel  Louis L'Amour                    Bantam\n",
       "B000FDJ0FS  The Wall Street Journal                 Dow Jones & Company Inc.\n",
       "111                                                                         \n",
       "111                                                                         "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_entry = pd.DataFrame({'title':'','authors':\", \".join([]), 'manufacturer':''},index=['111'])\n",
    "dataframe_ebooks = dataframe_ebooks.append(new_entry)\n",
    "dataframe_ebooks[['title', 'authors', 'manufacturer']].dropna(thresh=1, subset=[], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = pd.Series()\n",
    "log = log.append(pd.Series(BeautifulSoup(responsebis, 'html.parser').prettify()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    <?xml version=\"1.0\" ?>\\n<itemlookupresponse xm...\n",
       "dtype: object"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bottlenose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_ASSOCIATE_TAG = pickle.load(open('amazon_access_epfl_new.txt', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,AWS_ASSOCIATE_TAG) = pd.read_csv('amazon_keys.csv', header=None, usecols=[1]).values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "def error_handler(err):\n",
    "    ex = err['exception']\n",
    "    if isinstance(ex, HTTPError) and ex.code == 503:\n",
    "        time.sleep(random.expovariate(0.1))\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amazon = bottlenose.Amazon(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_ASSOCIATE_TAG, ErrorHandler=error_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books_asin_unique = pd.read_csv('books_asin.csv',usecols=[1]).asin.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367982"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(books_asin_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BEGIN = 367950\n",
    "END = 400000\n",
    "SIMULTANEOUS_REQUESTS = 10\n",
    "STEP = 50\n",
    "override = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are entries that are still not available through the Advertising API : B000FC26RI\n",
    "\n",
    "Also newspaper don't comply to this contract of authors : The Wall Street Journal (B000FDJ0FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe_books = pd.DataFrame(columns=['title', 'authors', 'manufacturer'])\n",
    "dataframe_undefined = pd.DataFrame(columns=['title', 'authors', 'manufacturer'])\n",
    "log = pd.Series()\n",
    "\n",
    "if(override):\n",
    "    dataframe_books.to_csv(amazon_aws_books)\n",
    "    dataframe_undefined.to_csv(amazon_aws_books_undefined)\n",
    "    log.to_csv(amazon_aws_books_log)\n",
    "\n",
    "books_simultaneous_list = []\n",
    "\n",
    "for i, book_asin in enumerate(books_asin_unique[BEGIN:END]):\n",
    "    books_simultaneous_list += [book_asin]\n",
    "    \n",
    "    if i>0 and i%SIMULTANEOUS_REQUESTS == 0:\n",
    "        keys = ','.join(books_simultaneous_list)\n",
    "        books_simultaneous_list = []\n",
    "        if i%STEP==0 and i > 0:\n",
    "            print(i+BEGIN)\n",
    "            dataframe_books[['title', 'authors', 'manufacturer']].to_csv(amazon_aws_books, header=False,mode='a')\n",
    "            dataframe_books = pd.DataFrame(columns=['title', 'authors', 'manufacturer'])\n",
    "\n",
    "            dataframe_undefined[['title', 'authors', 'manufacturer']].to_csv(amazon_aws_books_undefined, header=False,mode='a')\n",
    "            dataframe_undefined = pd.DataFrame(columns=['title', 'authors', 'manufacturer'])\n",
    "\n",
    "            log.to_csv(amazon_aws_books_log, header=False,mode='a')\n",
    "            log = pd.Series()\n",
    "\n",
    "        response = amazon.ItemLookup(ItemId=keys)\n",
    "        soup = BeautifulSoup(response, 'html.parser')\n",
    "        \n",
    "        items = soup.find_all('item')\n",
    "        for item in items:\n",
    "            all_important_defined = True\n",
    "            authors_retrieved = []\n",
    "            \n",
    "            asins = item.find_all('asin')\n",
    "            if(len(asins) != 0):\n",
    "                asin_retrieved = asins[0].text.strip()\n",
    "            else:\n",
    "                asin_retrieved = ''\n",
    "                all_important_defined = False\n",
    "\n",
    "            titles = item.find_all('title')\n",
    "            if(len(titles) != 0):\n",
    "                title_retrieved = titles[0].text.strip()\n",
    "            else:\n",
    "                title_retrieved = ''\n",
    "                all_important_defined = False\n",
    "\n",
    "            manufacturers = item.find_all('manufacturer')\n",
    "            if(len(manufacturers) != 0):\n",
    "                manufacturer_retrieved = manufacturers[0].text.strip()\n",
    "            else:\n",
    "                manufacturer_retrieved = ''\n",
    "\n",
    "            authors = item.find_all('author')\n",
    "            if(len(authors) != 0):\n",
    "                for author in authors:\n",
    "                    authors_retrieved += [author.text.strip()]\n",
    "            else:\n",
    "                authors_retrieved = []\n",
    "                all_important_defined = False\n",
    "\n",
    "            new_entry = pd.DataFrame({'title':title_retrieved,'authors':\", \".join(authors_retrieved), 'manufacturer':manufacturer_retrieved},index=[asin_retrieved])\n",
    "            if(all_important_defined):\n",
    "                dataframe_books = dataframe_books.append(new_entry)\n",
    "            else:\n",
    "                dataframe_undefined = dataframe_undefined.append(new_entry)\n",
    "                log = log.append(pd.Series(item.prettify()))\n",
    "\n",
    "dataframe_books[['title', 'authors', 'manufacturer']].to_csv(amazon_aws_books, header=False,mode='a')\n",
    "dataframe_undefined[['title', 'authors', 'manufacturer']].to_csv(amazon_aws_books_undefined, header=False,mode='a')\n",
    "log.to_csv(amazon_aws_books_log, header=False,mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataframe_ebooks = pd.DataFrame(columns=['title', 'authors', 'manufacturer'])\n",
    "dataframe_undefined = pd.DataFrame(columns=['title', 'authors', 'manufacturer'])\n",
    "log = pd.Series()\n",
    "\n",
    "if(override):\n",
    "    dataframe_ebooks.to_csv(amazon_aws_ebooks)\n",
    "    dataframe_undefined.to_csv(amazon_aws_ebooks_undefined)\n",
    "    log.to_csv(amazon_aws_ebooks_log)\n",
    "\n",
    "for i, ebook_asin in enumerate(ebooks_asin_unique[BEGIN:END]):\n",
    "    \n",
    "    if i%STEP==0:\n",
    "        if i > 0:\n",
    "            print(i+BEGIN)\n",
    "            dataframe_ebooks[['title', 'authors', 'manufacturer']].to_csv(amazon_aws_ebooks, header=False,mode='a')\n",
    "            dataframe_ebooks = pd.DataFrame(columns=['title', 'authors', 'manufacturer'])\n",
    "            \n",
    "            dataframe_undefined[['title', 'authors', 'manufacturer']].to_csv(amazon_aws_ebooks_undefined, header=False,mode='a')\n",
    "            dataframe_undefined = pd.DataFrame(columns=['title', 'authors', 'manufacturer'])\n",
    "            \n",
    "            log.to_csv(amazon_aws_ebooks_log, header=False,mode='a')\n",
    "            log = pd.Series()\n",
    "            \n",
    "    all_important_defined = True\n",
    "    \n",
    "    response = amazon.ItemLookup(ItemId=ebook_asin)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "\n",
    "    authors_retrieved = []\n",
    "\n",
    "    titles = soup.find_all('title')\n",
    "    if(len(titles) != 0):\n",
    "        title_retrieved = titles[0].text.strip()\n",
    "    else:\n",
    "        title_retrieved = ''\n",
    "        all_important_defined = False\n",
    "\n",
    "    manufacturers = soup.find_all('manufacturer')\n",
    "    if(len(manufacturers) != 0):\n",
    "        manufacturer_retrieved = manufacturers[0].text.strip()\n",
    "    else:\n",
    "        manufacturer_retrieved = ''\n",
    "\n",
    "    authors = soup.find_all('author')\n",
    "    if(len(authors) != 0):\n",
    "        for author in authors:\n",
    "            authors_retrieved += [author.text.strip()]\n",
    "    else:\n",
    "        authors_retrieved = []\n",
    "        all_important_defined = False\n",
    "\n",
    "    new_entry = pd.DataFrame({'title':title_retrieved,'authors':\", \".join(authors_retrieved), 'manufacturer':manufacturer_retrieved},index=[ebook_asin])\n",
    "    if(all_important_defined):\n",
    "        dataframe_ebooks = dataframe_ebooks.append(new_entry)\n",
    "    else:\n",
    "        dataframe_undefined = dataframe_undefined.append(new_entry)\n",
    "        log = log.append(pd.Series(soup.prettify()))\n",
    "\n",
    "dataframe_ebooks[['title', 'authors', 'manufacturer']].to_csv(amazon_aws_ebooks, header=False,mode='a')\n",
    "dataframe_undefined[['title', 'authors', 'manufacturer']].to_csv(amazon_aws_ebooks_undefined, header=False,mode='a')\n",
    "log.to_csv(amazon_aws_ebooks_log, header=False,mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- --\n",
    "## Review analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if we have some problems that will need to be fixed for the milestone 3, we have continued in the analysis. Of course we had to test with wrong data, but we will ensure that in the future, we will make it work on correct data (one with same author and title for books and ebooks). The code is here to show that we have worked on other steps of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you will need to uncomment this and download vader_lexicon as described in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download_shell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"Pi\")\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, array, col\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to fetch the reviews of the books for which we have the ebooks.\n",
    "\n",
    "As the file for the reviews of the books is quite big, we are going the read it into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_matched(list_asins, in_path, out_path):\n",
    "    pd.DataFrame(columns=[['asin','overall', 'summary', 'reviewerID', 'helpful','reviewText', 'reviewerName']]).to_csv(out_path)\n",
    "    \n",
    "    for chunk in pd.read_json(in_path, lines=True, chunksize=50000):\n",
    "        \n",
    "        # look if some asins of the chunk match the ones in the given list\n",
    "        filtered = chunk[chunk['asin'].isin(list_asins)].dropna(how='all')\n",
    "        \n",
    "        if len(filtered) > 0:\n",
    "            # write the data if any\n",
    "            filtered[['asin','overall', 'summary', 'reviewerID', 'helpful','reviewText', 'reviewerName']].to_csv(out_path,header=False, mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if WRITE_FIND_MATCHED:\n",
    "    find_matched(merged_metadatas['asin_book'].values, books_5core_path, matched_books_path)\n",
    "    find_matched(merged_metadatas['asin_ebook'].values, kindle_5core_path, matched_ebooks_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49083\n",
      "326418\n"
     ]
    }
   ],
   "source": [
    "ebooks_metadata = pd.read_csv('ebooks_metadata_amazon.csv')\n",
    "ebooks_metadata.columns=['asin_e', 'title_e', 'authors_e', 'manufacturer_e']\n",
    "\n",
    "# merging the two files to obtain the dataset for the books\n",
    "yves = pd.read_csv('books_metadata_amazon_Y.csv', encoding='latin1')\n",
    "yves.columns=['asin', 'title', 'authors', 'manufacturer']\n",
    "pa = pd.read_csv('books_metadata_amazon_p.csv', header=None)\n",
    "pa.columns=['asin', 'title', 'authors', 'manufacturer']\n",
    "\n",
    "books_metadata = pd.concat([yves, pa], axis=0)\n",
    "books_metadata.columns=['asin_b', 'title_b', 'authors_b', 'manufacturer_b']\n",
    "\n",
    "# remove the duplicated entries\n",
    "ebooks = ebooks_metadata.copy().set_index('title_e')\n",
    "print(len(ebooks))\n",
    "ebooks = ebooks[~ebooks.index.duplicated()]\n",
    "\n",
    "books = books_metadata.copy().set_index('title_b')\n",
    "print(len(books))\n",
    "books = books[~books.index.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271659"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54759"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317480"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48751"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we merge the dataset of the paperback books with the dataset of the kindle on the authors to obtain the authors who have books on both supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ebooks_by_auth = ebooks.reset_index().groupby(ebooks['authors_e'])\n",
    "cross_auth = ebooks.reset_index().merge(books.reset_index(), left_on='authors_e', right_on='authors_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ebooks_author = ebooks[ebooks['authors_e'].isin(cross_auth['authors_e'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46593"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ebooks_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count_author_e = ebooks_author.groupby('authors_e').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1525"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_author_e[count_author_e['asin_e']>5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books_author = books[books['authors_b'].isin(cross_auth['authors_b'].unique())]\n",
    "count_author_b = books_author.groupby('authors_b').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3424"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_author_b[count_author_b['asin_b']>5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin_b</th>\n",
       "      <th>manufacturer_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21028.000000</td>\n",
       "      <td>21028.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.709197</td>\n",
       "      <td>2.860614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.614053</td>\n",
       "      <td>6.444861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>243.000000</td>\n",
       "      <td>243.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin_b  manufacturer_b\n",
       "count  21028.000000    21028.000000\n",
       "mean       3.709197        2.860614\n",
       "std        6.614053        6.444861\n",
       "min        1.000000        0.000000\n",
       "25%        1.000000        0.000000\n",
       "50%        2.000000        1.000000\n",
       "75%        4.000000        3.000000\n",
       "max      243.000000      243.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_author_b.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin_e</th>\n",
       "      <th>manufacturer_e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21028.000000</td>\n",
       "      <td>21028.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.215712</td>\n",
       "      <td>1.364134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.859643</td>\n",
       "      <td>2.431707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin_e  manufacturer_e\n",
       "count  21028.000000    21028.000000\n",
       "mean       2.215712        1.364134\n",
       "std        2.859643        2.431707\n",
       "min        1.000000        0.000000\n",
       "25%        1.000000        0.000000\n",
       "50%        1.000000        1.000000\n",
       "75%        2.000000        1.000000\n",
       "max       63.000000       63.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_author_e.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_e</th>\n",
       "      <th>asin_e</th>\n",
       "      <th>authors_e</th>\n",
       "      <th>manufacturer_e</th>\n",
       "      <th>title_b</th>\n",
       "      <th>asin_b</th>\n",
       "      <th>authors_b</th>\n",
       "      <th>manufacturer_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ylesia: Star Wars Legends (The New Jedi Order)...</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>Walter Jon Williams</td>\n",
       "      <td>Del Rey</td>\n",
       "      <td>City on Fire</td>\n",
       "      <td>0061054429</td>\n",
       "      <td>Walter Jon Williams</td>\n",
       "      <td>Eos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ylesia: Star Wars Legends (The New Jedi Order)...</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>Walter Jon Williams</td>\n",
       "      <td>Del Rey</td>\n",
       "      <td>Days of Atonement</td>\n",
       "      <td>0312851189</td>\n",
       "      <td>Walter Jon Williams</td>\n",
       "      <td>Tor Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ylesia: Star Wars Legends (The New Jedi Order)...</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>Walter Jon Williams</td>\n",
       "      <td>Del Rey</td>\n",
       "      <td>Aristoi</td>\n",
       "      <td>0312851723</td>\n",
       "      <td>Walter Jon Williams</td>\n",
       "      <td>Tor Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ylesia: Star Wars Legends (The New Jedi Order)...</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>Walter Jon Williams</td>\n",
       "      <td>Del Rey</td>\n",
       "      <td>Hardwired</td>\n",
       "      <td>0312933037</td>\n",
       "      <td>Walter Jon Williams</td>\n",
       "      <td>Tor Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ylesia: Star Wars Legends (The New Jedi Order)...</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>Walter Jon Williams</td>\n",
       "      <td>Del Rey</td>\n",
       "      <td>This Is Not a Game (Dagmar Shaw)</td>\n",
       "      <td>0316003166</td>\n",
       "      <td>Walter Jon Williams</td>\n",
       "      <td>Orbit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title_e      asin_e  \\\n",
       "0  Ylesia: Star Wars Legends (The New Jedi Order)...  B000FA64QO   \n",
       "1  Ylesia: Star Wars Legends (The New Jedi Order)...  B000FA64QO   \n",
       "2  Ylesia: Star Wars Legends (The New Jedi Order)...  B000FA64QO   \n",
       "3  Ylesia: Star Wars Legends (The New Jedi Order)...  B000FA64QO   \n",
       "4  Ylesia: Star Wars Legends (The New Jedi Order)...  B000FA64QO   \n",
       "\n",
       "             authors_e manufacturer_e                           title_b  \\\n",
       "0  Walter Jon Williams        Del Rey                      City on Fire   \n",
       "1  Walter Jon Williams        Del Rey                 Days of Atonement   \n",
       "2  Walter Jon Williams        Del Rey                           Aristoi   \n",
       "3  Walter Jon Williams        Del Rey                         Hardwired   \n",
       "4  Walter Jon Williams        Del Rey  This Is Not a Game (Dagmar Shaw)   \n",
       "\n",
       "       asin_b            authors_b manufacturer_b  \n",
       "0  0061054429  Walter Jon Williams            Eos  \n",
       "1  0312851189  Walter Jon Williams      Tor Books  \n",
       "2  0312851723  Walter Jon Williams      Tor Books  \n",
       "3  0312933037  Walter Jon Williams      Tor Books  \n",
       "4  0316003166  Walter Jon Williams          Orbit  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_auth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of authors in common on both supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21029"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cross_auth['authors_e'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New analysis Here !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_books_authors = 'scores_books_by_authors.csv'\n",
    "scores_ebooks_authors = 'scores_ebooks_by_authors.csv'\n",
    "\n",
    "scores_books_overall = 'scores_books_by_overall.csv'\n",
    "scores_ebooks_overall = 'scores_ebooks_by_overall.csv'\n",
    "\n",
    "scores_books_authors_complete = 'scores_books_by_authors_complete.csv'\n",
    "scores_ebooks_authors_complete = 'scores_ebooks_by_authors_complete.csv'\n",
    "\n",
    "scores_books_overall_complete = 'scores_books_by_overall_complete.csv'\n",
    "scores_ebooks_overall_complete = 'scores_ebooks_by_overall_complete.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will obtain the reviews of the books and ebooks corresponding to the authors we find above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WRITE_FIND_MATCHED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if WRITE_FIND_MATCHED:\n",
    "    find_matched(cross_auth['asin_b'].unique(), books_5core_path, matched_books_path)\n",
    "    find_matched(cross_auth['asin_e'].unique(), kindle_5core_path, matched_ebooks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "match_books_author = pd.read_csv(matched_books_path)\n",
    "match_ebooks_author = pd.read_csv(matched_ebooks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_books_author = match_books_author.merge(\n",
    "    cross_auth[['asin_b', 'authors_b']].drop_duplicates() , left_on ='asin', right_on='asin_b')\n",
    "match_ebooks_author = match_ebooks_author.merge(\n",
    "    cross_auth[['asin_e', 'authors_e']].drop_duplicates() , left_on ='asin', right_on='asin_e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the \"helpful\" column which is a string representation of a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def literal_left(x):\n",
    "    l = literal_eval(x)\n",
    "    return l[0]\n",
    "\n",
    "def literal_right(x):\n",
    "    l = literal_eval(x)\n",
    "    return l[1]\n",
    "\n",
    "def parse_help(source):\n",
    "    target = source.copy()\n",
    "    target['helpful'] = source['helpful'].apply(literal_left)\n",
    "    target['not_helpful'] = source['helpful'].apply(literal_right)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matched_booksh = parse_help(match_books_author)\n",
    "matched_ebooksh = parse_help(match_ebooks_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matched_booksh = matched_booksh.drop(['reviewerID', 'reviewerName', 'asin_b'], axis=1)\n",
    "matched_ebooksh = matched_ebooksh.drop(['reviewerID', 'reviewerName', 'asin_e'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2648868"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matched_booksh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>authors_b</th>\n",
       "      <th>not_helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>5</td>\n",
       "      <td>Great</td>\n",
       "      <td>0</td>\n",
       "      <td>for getting your kid introduced to his/her ABC...</td>\n",
       "      <td>Stan Berenstain, Jan Berenstain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>3</td>\n",
       "      <td>A celebration of B</td>\n",
       "      <td>1</td>\n",
       "      <td>This Book is funny and is full of B words, lik...</td>\n",
       "      <td>Stan Berenstain, Jan Berenstain</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>270</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>5</td>\n",
       "      <td>Big B Believer</td>\n",
       "      <td>2</td>\n",
       "      <td>A favorite Berenstain book of my children I wa...</td>\n",
       "      <td>Stan Berenstain, Jan Berenstain</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>5</td>\n",
       "      <td>Very funny book, sad ending though!</td>\n",
       "      <td>0</td>\n",
       "      <td>This book is quite funny.  Especially when you...</td>\n",
       "      <td>Stan Berenstain, Jan Berenstain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>272</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>5</td>\n",
       "      <td>Child's book</td>\n",
       "      <td>0</td>\n",
       "      <td>Teaching the next generation to love books!  M...</td>\n",
       "      <td>Stan Berenstain, Jan Berenstain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        asin  overall                              summary  \\\n",
       "0         268  000171287X        5                                Great   \n",
       "1         269  000171287X        3                   A celebration of B   \n",
       "2         270  000171287X        5                       Big B Believer   \n",
       "3         271  000171287X        5  Very funny book, sad ending though!   \n",
       "4         272  000171287X        5                         Child's book   \n",
       "\n",
       "   helpful                                         reviewText  \\\n",
       "0        0  for getting your kid introduced to his/her ABC...   \n",
       "1        1  This Book is funny and is full of B words, lik...   \n",
       "2        2  A favorite Berenstain book of my children I wa...   \n",
       "3        0  This book is quite funny.  Especially when you...   \n",
       "4        0  Teaching the next generation to love books!  M...   \n",
       "\n",
       "                         authors_b  not_helpful  \n",
       "0  Stan Berenstain, Jan Berenstain            0  \n",
       "1  Stan Berenstain, Jan Berenstain            3  \n",
       "2  Stan Berenstain, Jan Berenstain            2  \n",
       "3  Stan Berenstain, Jan Berenstain            0  \n",
       "4  Stan Berenstain, Jan Berenstain            0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_booksh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "booksh_by_author = matched_booksh.dropna(subset=['authors_b']).rename(columns ={'authors_b':'authors'})\n",
    "booksh_by_author.set_index('authors', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ebooksh_by_author = matched_ebooksh.dropna(subset=['authors_e']).rename(columns ={'authors_e':'authors'})\n",
    "ebooksh_by_author.set_index('authors', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our reviews it is time to analyse their content. To compute the score of a book, we use two approaches:\n",
    "\n",
    "1) A weighted average of the stars taking into account the helpfulness of the review as described below.\n",
    "\n",
    "Let $s_{i,j}$ be the $j$th rating of book $i$ and $n$ the number of ratings for this book. As other users can review a review by saying whether it is helpful, let $k_{i,j}$ be the number of the person who reviewed the review $s_{i,j}$ and let $u_{i,j}$ be the number of reviewer who found the review helpful among the $k_{i,j}$ reviewers. Then what we want to do is to give more weight to reviews which are helpful and less weight to reviews that the other users found useless. The maximum weight a review can have is 1 and the minimum is 0, then if a review has never been reviewed or it has been voted equally helpful and not helpful, its weight will be 0.5 which is neutral.\n",
    "$$w_{i,j}=\\cases{\\frac{u_{i,j}}{k_{i,j}}, \\text{if } k_{i,j} \\ne 0 \\\\0.5, \\text{if } k_{i,j}=0}$$\n",
    "\n",
    "    \n",
    "The weighted average is then:\n",
    "\n",
    "$$S_i = \\frac{\\sum_{j=1}^{n} w_{i,j}s_{i,j}}{\\sum_{j=1}^{n} w_{i,j}}$$\n",
    "\n",
    "2) A weighted average of the sentiment's intensity in the review taking into account the helpfulness with the weight being derived similarly as above.\n",
    "\n",
    "Here we are going to use the VADER (Valence Aware Dictionary sEntiment Reasoner) sentiment analyzer from the nltk package. VADER is based on lexicons of sentiment-related words and each words is rated as whether it is positive and negative, and how negative or positive it is. For example, the 'excellent' would be treated as more positive than 'good'.\n",
    "\n",
    "The score Vader returns is between -1 and 1, 1 for a very positive review, -1 for a very negative review, and 0 if it is neutral.\n",
    "\n",
    "Although Vader is not the most accurate tool and to analyse a piece of text it checks if any of the words in the text are present in the lexicon, therefore its accuracy depends on the coverage of the lexicons. It is the easiest approach we have for the moment as we cannot train a classifier since we don't have a proper training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the weight of a review\n",
    "def weighted_helpful(data):\n",
    "    voters = int(data[0]) + int(data[1])\n",
    "    \n",
    "    return 0.5 if voters == 0 else int(data[0])/voters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the weighted average of the two scores for a book\n",
    "def weighted_scores(data, groupby_key):\n",
    "\n",
    "    data['weighted_help'] = data[['helpful', 'not_helpful']].apply(weighted_helpful)\n",
    "    \n",
    "    func = lambda x: sid.polarity_scores(x)['compound']\n",
    "    \n",
    "    data['sentiment_review'] = data['reviewText'].astype(str).apply(func)\n",
    "    data['sentiment_summary'] = data['summary'].astype(str).apply(func)\n",
    "    \n",
    "    data['sentiment_average'] = (data['sentiment_review'] + data['sentiment_summary'])*0.5\n",
    "    data['sentiment_rescaled'] = (data['sentiment_average'] + 1) * 2 + 1\n",
    "    \n",
    "    data['combined'] = (data['sentiment_rescaled'] + data['overall']) * 0.5\n",
    "    \n",
    "    # multiply the scores with the weight\n",
    "    data['weighted_sentiment_review'] = data['weighted_help'] * data['sentiment_review']\n",
    "    data['weighted_sentiment_summary'] = data['weighted_help'] * data['sentiment_summary']\n",
    "    data['weighted_sentiment_average'] = data['weighted_help'] * data['sentiment_average']\n",
    "    data['weighted_sentiment_rescaled'] = data['weighted_help'] * data['sentiment_rescaled']\n",
    "    data['weighted_overall'] = data['weighted_help'] * data['overall']\n",
    "    data['weighted_combined'] = data['weighted_help'] * data['combined']\n",
    "    \n",
    "    # sum everything\n",
    "    weighted_score = data.groupby(data[groupby_key]).sum()\n",
    "    \n",
    "    # divide by the sum of the weights to obtain the weighted average\n",
    "    weighted_score['sentiment_review_score'] = weighted_score['weighted_sentiment_review']/weighted_score['weighted_help']\n",
    "    weighted_score['sentiment_summary_score'] = weighted_score['weighted_sentiment_summary']/weighted_score['weighted_help']\n",
    "    weighted_score['sentiment_average_score'] = weighted_score['weighted_sentiment_average']/weighted_score['weighted_help']\n",
    "    weighted_score['sentiment_rescaled'] = weighted_score['weighted_sentiment_rescaled']/weighted_score['weighted_help']\n",
    "    weighted_score['overall_score'] = weighted_score['weighted_overall']/weighted_score['weighted_help']\n",
    "    weighted_score['combined_score'] = weighted_score['weighted_combined']/weighted_score['weighted_help']\n",
    "    \n",
    "    return weighted_score[['sentiment_review_score', 'sentiment_summary_score', 'sentiment_average_score', 'sentiment_rescaled', 'overall_score', 'combined_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same functions but translated to pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute the weighted average of the two scores for a book\n",
    "def weighted_helpful_sp(helpful, not_helpful):\n",
    "    voters = int(helpful) + int(not_helpful)\n",
    "    \n",
    "    return 0.5 if voters == 0 else int(helpful)/voters\n",
    "\n",
    "helpful_spark = udf(weighted_helpful_sp, T.FloatType())\n",
    "\n",
    "# user defined functions to use with spark\n",
    "average = udf(lambda x, y: (float(x) + float(y))*0.5, T.FloatType())\n",
    "rescale = udf(lambda x: (float(x) + 1) * 2 + 1 , T.FloatType())\n",
    "times = udf(lambda x, y: float(x)*float(y), T.FloatType())\n",
    "div = udf(lambda x, y: float(x)/float(y), T.FloatType())\n",
    "\n",
    "def weighted_scores_spark(data, groupby_key):\n",
    "    # get the weight\n",
    "    data = data.withColumn('weighted_help', helpful_spark('helpful', 'not_helpful'))\n",
    "    #data['weighted_help'] = (data['helpful'].astype(list)).apply(weighted_helpful)\n",
    "    \n",
    "    func = udf(lambda x: sid.polarity_scores(x)['compound'], T.DoubleType())\n",
    "    \n",
    "    data = data.withColumn('sentiment_review', func('reviewText'))\n",
    "    \n",
    "    data = data.withColumn('sentiment_summary', func('summary'))\n",
    "    \n",
    "    #print(data.select('sentiment_review').show())\n",
    "    \n",
    "    data = data.withColumn('sentiment_average', average('sentiment_review','sentiment_summary'))\n",
    "    data = data.withColumn('sentiment_rescaled', rescale('sentiment_average'))\n",
    "    \n",
    "    data = data.withColumn('combined', average('sentiment_rescaled','overall'))\n",
    "    \n",
    "    # multiply the scores with the weight\n",
    "    data = data.withColumn('weighted_sentiment_review',times('weighted_help','sentiment_review'))\n",
    "    data = data.withColumn('weighted_sentiment_summary', times('weighted_help', 'sentiment_summary'))\n",
    "    data = data.withColumn('weighted_sentiment_average', times('weighted_help', 'sentiment_average'))\n",
    "    data = data.withColumn('weighted_sentiment_rescaled', times('weighted_help','sentiment_rescaled'))\n",
    "    data = data.withColumn('weighted_overall', times('weighted_help','overall'))\n",
    "    data = data.withColumn('weighted_combined', times('weighted_help', 'combined'))\n",
    "\n",
    "\n",
    "    w = data.groupby(groupby_key).agg(\n",
    "        F.sum('weighted_help').alias('weighted_help'),\n",
    "        F.sum('weighted_sentiment_review').alias('weighted_sentiment_review'),\n",
    "        F.sum('weighted_sentiment_summary').alias('weighted_sentiment_summary'),\n",
    "        F.sum('weighted_sentiment_average').alias('weighted_sentiment_average'),\n",
    "        F.sum('weighted_sentiment_rescaled').alias('weighted_sentiment_rescaled'),\n",
    "        F.sum('weighted_overall').alias('weighted_overall'),\n",
    "        F.sum('weighted_combined').alias('weighted_combined')\n",
    "    )\n",
    "\n",
    "    # divide by the sum of the weights to obtain the weighted average\n",
    "    w = w.withColumn('sentiment_review_score', div('weighted_sentiment_review','weighted_help'))\n",
    "    w = w.withColumn('sentiment_summary_score', div('weighted_sentiment_summary', 'weighted_help'))\n",
    "    w = w.withColumn('sentiment_average_score', div('weighted_sentiment_average', 'weighted_help'))\n",
    "    w = w.withColumn('sentiment_rescaled', div('weighted_sentiment_rescaled','weighted_help'))\n",
    "    w = w.withColumn('overall_score', div('weighted_overall', 'weighted_help'))\n",
    "    w = w.withColumn('combined_score', div('weighted_combined', 'weighted_help'))\n",
    "    \n",
    "    return w.select([groupby_key,'sentiment_review_score', 'sentiment_summary_score', 'sentiment_average_score', 'sentiment_rescaled', 'overall_score', 'combined_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute only the sentiment score without grouping or rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_review(data):\n",
    "    func = udf(lambda x: sid.polarity_scores(x)['compound'], T.DoubleType())\n",
    "    \n",
    "    data = data.withColumn('sentiment_review', func('reviewText'))\n",
    "    data = data.withColumn('sentiment_summary', func('summary'))\n",
    "    data = data.withColumn('average', average('sentiment_review', 'sentiment_summary'))\n",
    "    \n",
    "    return data.select(['overall', 'asin', 'sentiment_review', 'sentiment_summary', 'average'])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the functions by batch to avoid runnning out of heap space for spark, and reduce the local memory usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_index(index, size):\n",
    "    \"\"\"\n",
    "    When given the authors as index, the index will be split such that \n",
    "    all the reviews for the same author stay together.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    n = len(index)\n",
    "    print(n)\n",
    "    partition = int(n/size)\n",
    "    for i in range(partition):\n",
    "        from_ = i*size\n",
    "        if (i+1)*size - 1 > n:\n",
    "            end = n\n",
    "        else:\n",
    "            end = (i+1)*size\n",
    "        out.append(index[from_:end])\n",
    "    return out\n",
    "\n",
    "# no spark version\n",
    "def compute_by_batch(data, size, path, last_batch=0, override=False):\n",
    "    indices = batch_index(data.index.unique(), size)\n",
    "    indices = indices[last_batch:]\n",
    "        \n",
    "    for i, index in enumerate(indices):\n",
    "        subdata = data.loc[index]\n",
    "        print(\"Batch {}/{} of length {}\".format(last_batch+i+1, len(indices), len(subdata)))\n",
    "        sparkdf = sqlContext.createDataFrame(subdata.reset_index().astype(str))\n",
    "        result = weighted_scores_spark(sparkdf, 'authors').toPandas()\n",
    "        \n",
    "        if last_batch == 0 and i == 0 and override:\n",
    "            result.to_csv(path)\n",
    "        else:\n",
    "            result.to_csv(path, header=False,mode='a')\n",
    "            \n",
    "        sqlContext.clearCache()\n",
    "\n",
    "# spark version\n",
    "def compute_by_batch_ns(data, size, path, last_batch=0, override = False):\n",
    "    indices = batch_index(data.index.unique(), size)\n",
    "    indices = indices[last_batch:]\n",
    "        \n",
    "    for i, index in enumerate(indices):\n",
    "        subdata = data.loc[index]\n",
    "        print(\"Batch {}/{} of length {}\".format(last_batch+i+1, len(indices), len(subdata)))\n",
    "        result = weighted_scores(subdata.reset_index(), 'authors')\n",
    "        \n",
    "        if last_batch == 0 and i == 0 and override:\n",
    "            result.to_csv(path)\n",
    "        else:\n",
    "            result.to_csv(path, header=False,mode='a')\n",
    "\n",
    "# spark version for any function\n",
    "def compute_by_batch_gen(data, function, size, path, last_batch=0, override = False):\n",
    "    indices = batch_index(data.index.unique(), size)\n",
    "    indices = indices[last_batch:]\n",
    "        \n",
    "    for i, index in enumerate(indices):\n",
    "        subdata = data.loc[index]\n",
    "        print(\"Batch {}/{} of length {}\".format(last_batch+i+1, len(indices), len(subdata)))\n",
    "        sparkdf = sqlContext.createDataFrame(subdata.reset_index().astype(str))\n",
    "        result = function(sparkdf).toPandas()\n",
    "        \n",
    "        if last_batch == 0 and i == 0 and override:\n",
    "            result.to_csv(path)\n",
    "        else:\n",
    "            result.to_csv(path, header=False,mode='a')\n",
    "        sqlContext.clearCache()\n",
    "        \n",
    "weight_by_author = lambda x: weighted_scores_spark(x, 'authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if WRITE_SCORES:\n",
    "    compute_by_batch_gen(booksh_by_author.reset_index(), compute_review, 20, scores_books_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if WRITE_SCORES:\n",
    "    compute_by_batch(ebooksh_by_author, 100, scores_ebooks_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WRITE_SCORES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WRITE_SCORES:\n",
    "    compute_by_batch_gen(ebooksh_by_author, compute_review, 200, scores_ebooks_overall_complete, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WRITE_SCORES:\n",
    "    compute_by_batch_gen(booksh_by_author.reset_index(), compute_review, 20000, scores_books_overall_complete, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis by stars on books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_books = pd.read_csv(scores_books_overall_complete)\n",
    "scores_ebooks = pd.read_csv(scores_ebooks_overall_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviews by star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_review</th>\n",
       "      <th>sentiment_summary</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002845</td>\n",
       "      <td>-0.132001</td>\n",
       "      <td>-0.067423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.198450</td>\n",
       "      <td>-0.048995</td>\n",
       "      <td>0.074727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.482513</td>\n",
       "      <td>0.134192</td>\n",
       "      <td>0.308352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.683320</td>\n",
       "      <td>0.300601</td>\n",
       "      <td>0.491960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.737726</td>\n",
       "      <td>0.352813</td>\n",
       "      <td>0.545270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment_review  sentiment_summary   average\n",
       "overall                                               \n",
       "1               -0.002845          -0.132001 -0.067423\n",
       "2                0.198450          -0.048995  0.074727\n",
       "3                0.482513           0.134192  0.308352\n",
       "4                0.683320           0.300601  0.491960\n",
       "5                0.737726           0.352813  0.545270"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_books.groupby('overall').agg('mean').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD8CAYAAACyyUlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+/+2iVzUdtVWLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120e1c240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(scores_books['overall'].values);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis by stars on ebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.639868e+06\n",
       "mean     4.701627e-01\n",
       "std      3.428241e-01\n",
       "min     -9.806500e-01\n",
       "25%      3.428000e-01\n",
       "50%      4.984500e-01\n",
       "75%      7.326500e-01\n",
       "max      9.914000e-01\n",
       "Name: average, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_books['average'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.639868e+06\n",
       "mean     4.300786e+00\n",
       "std      1.007949e+00\n",
       "min      1.000000e+00\n",
       "25%      4.000000e+00\n",
       "50%      5.000000e+00\n",
       "75%      5.000000e+00\n",
       "max      5.000000e+00\n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_books['overall'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>asin</th>\n",
       "      <th>sentiment_review</th>\n",
       "      <th>sentiment_summary</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>0.9427</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.47135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.40630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>0.8426</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.42130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.40100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>-0.5145</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>-0.09815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  overall        asin  sentiment_review  sentiment_summary  \\\n",
       "0           0        2  B000FA64QO            0.9427             0.0000   \n",
       "1           1        5  B000FA64QO            0.8126             0.0000   \n",
       "2           2        4  B000FA64QO            0.8426             0.0000   \n",
       "3           3        5  B000FA64QO            0.8020             0.0000   \n",
       "4           4        3  B000FA64QO           -0.5145             0.3182   \n",
       "\n",
       "   average  \n",
       "0  0.47135  \n",
       "1  0.40630  \n",
       "2  0.42130  \n",
       "3  0.40100  \n",
       "4 -0.09815  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_ebooks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_review</th>\n",
       "      <th>sentiment_summary</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.011571</td>\n",
       "      <td>-0.118283</td>\n",
       "      <td>-0.064927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.195780</td>\n",
       "      <td>-0.029333</td>\n",
       "      <td>0.083224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.511636</td>\n",
       "      <td>0.166198</td>\n",
       "      <td>0.338917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.713358</td>\n",
       "      <td>0.312480</td>\n",
       "      <td>0.512919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.761150</td>\n",
       "      <td>0.354392</td>\n",
       "      <td>0.557771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment_review  sentiment_summary   average\n",
       "overall                                               \n",
       "1               -0.011571          -0.118283 -0.064927\n",
       "2                0.195780          -0.029333  0.083224\n",
       "3                0.511636           0.166198  0.338917\n",
       "4                0.713358           0.312480  0.512919\n",
       "5                0.761150           0.354392  0.557771"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_ebooks.groupby('overall').agg('mean').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120e6e748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(scores_ebooks['overall'].values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    753133.000000\n",
       "mean          0.495981\n",
       "std           0.325695\n",
       "min          -0.980650\n",
       "25%           0.381550\n",
       "50%           0.538050\n",
       "75%           0.743800\n",
       "max           0.991400\n",
       "Name: average, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_ebooks['average'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    753133.000000\n",
       "mean          4.364309\n",
       "std           0.939496\n",
       "min           1.000000\n",
       "25%           4.000000\n",
       "50%           5.000000\n",
       "75%           5.000000\n",
       "max           5.000000\n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_ebooks['overall'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_books_by_authors = pd.read_csv(scores_books_authors)\n",
    "scores_ebooks_by_authors = pd.read_csv(scores_ebooks_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2814"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores_books_by_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3168"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores_ebooks_by_authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviews per authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>sentiment_average_score_book</th>\n",
       "      <th>overall_score_book</th>\n",
       "      <th>combined_score_book</th>\n",
       "      <th>sentiment_average_score_kindle</th>\n",
       "      <th>overall_score_kindle</th>\n",
       "      <th>combined_score_kindle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jon Evans</td>\n",
       "      <td>0.423018</td>\n",
       "      <td>4.265808</td>\n",
       "      <td>4.055922</td>\n",
       "      <td>0.458332</td>\n",
       "      <td>4.282822</td>\n",
       "      <td>4.099743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agatha Christie</td>\n",
       "      <td>0.289064</td>\n",
       "      <td>4.333456</td>\n",
       "      <td>3.955791</td>\n",
       "      <td>0.397621</td>\n",
       "      <td>4.377827</td>\n",
       "      <td>4.086535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James Patterson</td>\n",
       "      <td>0.294031</td>\n",
       "      <td>3.959031</td>\n",
       "      <td>3.773546</td>\n",
       "      <td>0.342400</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.509067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stella Riley</td>\n",
       "      <td>0.132290</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>3.932290</td>\n",
       "      <td>0.753520</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4.453520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Philip K. Dick</td>\n",
       "      <td>0.269942</td>\n",
       "      <td>4.169998</td>\n",
       "      <td>3.854941</td>\n",
       "      <td>0.267467</td>\n",
       "      <td>4.229118</td>\n",
       "      <td>3.882026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           authors  sentiment_average_score_book  overall_score_book  \\\n",
       "0        Jon Evans                      0.423018            4.265808   \n",
       "1  Agatha Christie                      0.289064            4.333456   \n",
       "2  James Patterson                      0.294031            3.959031   \n",
       "3     Stella Riley                      0.132290            4.600000   \n",
       "4   Philip K. Dick                      0.269942            4.169998   \n",
       "\n",
       "   combined_score_book  sentiment_average_score_kindle  overall_score_kindle  \\\n",
       "0             4.055922                        0.458332              4.282822   \n",
       "1             3.955791                        0.397621              4.377827   \n",
       "2             3.773546                        0.342400              3.333333   \n",
       "3             3.932290                        0.753520              4.400000   \n",
       "4             3.854941                        0.267467              4.229118   \n",
       "\n",
       "   combined_score_kindle  \n",
       "0               4.099743  \n",
       "1               4.086535  \n",
       "2               3.509067  \n",
       "3               4.453520  \n",
       "4               3.882026  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_books_by_authors = scores_books_by_authors[['authors', 'sentiment_average_score', 'overall_score','combined_score']]\n",
    "scores_ebooks_by_authors = scores_ebooks_by_authors[['authors', 'sentiment_average_score', 'overall_score','combined_score']]\n",
    "\n",
    "scores_by_authors = scores_books_by_authors.merge(scores_ebooks_by_authors, on='authors', suffixes=('_book', '_kindle'))\n",
    "scores_by_authors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2772"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores_by_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_average_score_book      0.462495\n",
       "overall_score_book                4.287626\n",
       "combined_score_book               4.106308\n",
       "sentiment_average_score_kindle    0.478348\n",
       "overall_score_kindle              4.336031\n",
       "combined_score_kindle             4.146363\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_by_authors.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>authors</th>\n",
       "      <th>not_helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>5</td>\n",
       "      <td>Great</td>\n",
       "      <td>0</td>\n",
       "      <td>for getting your kid introduced to his/her ABC...</td>\n",
       "      <td>Stan Berenstain, Jan Berenstain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>3</td>\n",
       "      <td>A celebration of B</td>\n",
       "      <td>1</td>\n",
       "      <td>This Book is funny and is full of B words, lik...</td>\n",
       "      <td>Stan Berenstain, Jan Berenstain</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>270</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>5</td>\n",
       "      <td>Big B Believer</td>\n",
       "      <td>2</td>\n",
       "      <td>A favorite Berenstain book of my children I wa...</td>\n",
       "      <td>Stan Berenstain, Jan Berenstain</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>5</td>\n",
       "      <td>Very funny book, sad ending though!</td>\n",
       "      <td>0</td>\n",
       "      <td>This book is quite funny.  Especially when you...</td>\n",
       "      <td>Stan Berenstain, Jan Berenstain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>272</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>5</td>\n",
       "      <td>Child's book</td>\n",
       "      <td>0</td>\n",
       "      <td>Teaching the next generation to love books!  M...</td>\n",
       "      <td>Stan Berenstain, Jan Berenstain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        asin  overall                              summary  \\\n",
       "0         268  000171287X        5                                Great   \n",
       "1         269  000171287X        3                   A celebration of B   \n",
       "2         270  000171287X        5                       Big B Believer   \n",
       "3         271  000171287X        5  Very funny book, sad ending though!   \n",
       "4         272  000171287X        5                         Child's book   \n",
       "\n",
       "   helpful                                         reviewText  \\\n",
       "0        0  for getting your kid introduced to his/her ABC...   \n",
       "1        1  This Book is funny and is full of B words, lik...   \n",
       "2        2  A favorite Berenstain book of my children I wa...   \n",
       "3        0  This book is quite funny.  Especially when you...   \n",
       "4        0  Teaching the next generation to love books!  M...   \n",
       "\n",
       "                           authors  not_helpful  \n",
       "0  Stan Berenstain, Jan Berenstain            0  \n",
       "1  Stan Berenstain, Jan Berenstain            3  \n",
       "2  Stan Berenstain, Jan Berenstain            2  \n",
       "3  Stan Berenstain, Jan Berenstain            0  \n",
       "4  Stan Berenstain, Jan Berenstain            0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_booksh = matched_booksh.dropna(subset=['authors_b']).rename(columns ={'authors_b':'authors'})\n",
    "matched_booksh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refined analysis on some specific authors\n",
    "Now we want to see which authors has the most reviews for the books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books_review_per_author = matched_booksh.groupby('authors').agg('count')\n",
    "most_reviewed_books_author = books_review_per_author.sort_values('overall', ascending =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>not_helpful</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authors</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stephen King</th>\n",
       "      <td>24266</td>\n",
       "      <td>24266</td>\n",
       "      <td>24266</td>\n",
       "      <td>24266</td>\n",
       "      <td>24266</td>\n",
       "      <td>24266</td>\n",
       "      <td>24266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nora Roberts</th>\n",
       "      <td>18560</td>\n",
       "      <td>18560</td>\n",
       "      <td>18560</td>\n",
       "      <td>18560</td>\n",
       "      <td>18560</td>\n",
       "      <td>18560</td>\n",
       "      <td>18560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lee Child</th>\n",
       "      <td>13727</td>\n",
       "      <td>13727</td>\n",
       "      <td>13727</td>\n",
       "      <td>13727</td>\n",
       "      <td>13727</td>\n",
       "      <td>13727</td>\n",
       "      <td>13727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H.M. Ward</th>\n",
       "      <td>13292</td>\n",
       "      <td>13292</td>\n",
       "      <td>13292</td>\n",
       "      <td>13292</td>\n",
       "      <td>13292</td>\n",
       "      <td>13292</td>\n",
       "      <td>13292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David Baldacci</th>\n",
       "      <td>12219</td>\n",
       "      <td>12219</td>\n",
       "      <td>12219</td>\n",
       "      <td>12219</td>\n",
       "      <td>12219</td>\n",
       "      <td>12219</td>\n",
       "      <td>12219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michael Connelly</th>\n",
       "      <td>11683</td>\n",
       "      <td>11683</td>\n",
       "      <td>11683</td>\n",
       "      <td>11683</td>\n",
       "      <td>11683</td>\n",
       "      <td>11683</td>\n",
       "      <td>11683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James Patterson</th>\n",
       "      <td>11493</td>\n",
       "      <td>11493</td>\n",
       "      <td>11493</td>\n",
       "      <td>11493</td>\n",
       "      <td>11493</td>\n",
       "      <td>11493</td>\n",
       "      <td>11493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dean Koontz</th>\n",
       "      <td>10840</td>\n",
       "      <td>10840</td>\n",
       "      <td>10840</td>\n",
       "      <td>10840</td>\n",
       "      <td>10840</td>\n",
       "      <td>10840</td>\n",
       "      <td>10840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abbi Glines</th>\n",
       "      <td>10696</td>\n",
       "      <td>10696</td>\n",
       "      <td>10696</td>\n",
       "      <td>10695</td>\n",
       "      <td>10696</td>\n",
       "      <td>10696</td>\n",
       "      <td>10696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debbie Macomber</th>\n",
       "      <td>9771</td>\n",
       "      <td>9771</td>\n",
       "      <td>9771</td>\n",
       "      <td>9771</td>\n",
       "      <td>9771</td>\n",
       "      <td>9771</td>\n",
       "      <td>9771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veronica Roth</th>\n",
       "      <td>9643</td>\n",
       "      <td>9643</td>\n",
       "      <td>9643</td>\n",
       "      <td>9642</td>\n",
       "      <td>9643</td>\n",
       "      <td>9642</td>\n",
       "      <td>9643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sylvia Day</th>\n",
       "      <td>9523</td>\n",
       "      <td>9523</td>\n",
       "      <td>9523</td>\n",
       "      <td>9523</td>\n",
       "      <td>9523</td>\n",
       "      <td>9523</td>\n",
       "      <td>9523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J.R. Ward</th>\n",
       "      <td>8762</td>\n",
       "      <td>8762</td>\n",
       "      <td>8762</td>\n",
       "      <td>8762</td>\n",
       "      <td>8762</td>\n",
       "      <td>8762</td>\n",
       "      <td>8762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jessica Sorensen</th>\n",
       "      <td>7816</td>\n",
       "      <td>7816</td>\n",
       "      <td>7816</td>\n",
       "      <td>7815</td>\n",
       "      <td>7816</td>\n",
       "      <td>7815</td>\n",
       "      <td>7816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hugh Howey</th>\n",
       "      <td>7615</td>\n",
       "      <td>7615</td>\n",
       "      <td>7615</td>\n",
       "      <td>7615</td>\n",
       "      <td>7615</td>\n",
       "      <td>7615</td>\n",
       "      <td>7615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kristen Ashley</th>\n",
       "      <td>7304</td>\n",
       "      <td>7304</td>\n",
       "      <td>7304</td>\n",
       "      <td>7304</td>\n",
       "      <td>7304</td>\n",
       "      <td>7304</td>\n",
       "      <td>7304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marie Force</th>\n",
       "      <td>7150</td>\n",
       "      <td>7150</td>\n",
       "      <td>7150</td>\n",
       "      <td>7150</td>\n",
       "      <td>7150</td>\n",
       "      <td>7150</td>\n",
       "      <td>7150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orson Scott Card</th>\n",
       "      <td>6827</td>\n",
       "      <td>6827</td>\n",
       "      <td>6827</td>\n",
       "      <td>6827</td>\n",
       "      <td>6827</td>\n",
       "      <td>6827</td>\n",
       "      <td>6827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Susan Mallery</th>\n",
       "      <td>6728</td>\n",
       "      <td>6728</td>\n",
       "      <td>6728</td>\n",
       "      <td>6728</td>\n",
       "      <td>6728</td>\n",
       "      <td>6727</td>\n",
       "      <td>6728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laurell K. Hamilton</th>\n",
       "      <td>6678</td>\n",
       "      <td>6678</td>\n",
       "      <td>6678</td>\n",
       "      <td>6678</td>\n",
       "      <td>6678</td>\n",
       "      <td>6678</td>\n",
       "      <td>6678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unnamed: 0   asin  overall  summary  helpful  reviewText  \\\n",
       "authors                                                                         \n",
       "Stephen King              24266  24266    24266    24266    24266       24266   \n",
       "Nora Roberts              18560  18560    18560    18560    18560       18560   \n",
       "Lee Child                 13727  13727    13727    13727    13727       13727   \n",
       "H.M. Ward                 13292  13292    13292    13292    13292       13292   \n",
       "David Baldacci            12219  12219    12219    12219    12219       12219   \n",
       "Michael Connelly          11683  11683    11683    11683    11683       11683   \n",
       "James Patterson           11493  11493    11493    11493    11493       11493   \n",
       "Dean Koontz               10840  10840    10840    10840    10840       10840   \n",
       "Abbi Glines               10696  10696    10696    10695    10696       10696   \n",
       "Debbie Macomber            9771   9771     9771     9771     9771        9771   \n",
       "Veronica Roth              9643   9643     9643     9642     9643        9642   \n",
       "Sylvia Day                 9523   9523     9523     9523     9523        9523   \n",
       "J.R. Ward                  8762   8762     8762     8762     8762        8762   \n",
       "Jessica Sorensen           7816   7816     7816     7815     7816        7815   \n",
       "Hugh Howey                 7615   7615     7615     7615     7615        7615   \n",
       "Kristen Ashley             7304   7304     7304     7304     7304        7304   \n",
       "Marie Force                7150   7150     7150     7150     7150        7150   \n",
       "Orson Scott Card           6827   6827     6827     6827     6827        6827   \n",
       "Susan Mallery              6728   6728     6728     6728     6728        6727   \n",
       "Laurell K. Hamilton        6678   6678     6678     6678     6678        6678   \n",
       "\n",
       "                     not_helpful  \n",
       "authors                           \n",
       "Stephen King               24266  \n",
       "Nora Roberts               18560  \n",
       "Lee Child                  13727  \n",
       "H.M. Ward                  13292  \n",
       "David Baldacci             12219  \n",
       "Michael Connelly           11683  \n",
       "James Patterson            11493  \n",
       "Dean Koontz                10840  \n",
       "Abbi Glines                10696  \n",
       "Debbie Macomber             9771  \n",
       "Veronica Roth               9643  \n",
       "Sylvia Day                  9523  \n",
       "J.R. Ward                   8762  \n",
       "Jessica Sorensen            7816  \n",
       "Hugh Howey                  7615  \n",
       "Kristen Ashley              7304  \n",
       "Marie Force                 7150  \n",
       "Orson Scott Card            6827  \n",
       "Susan Mallery               6728  \n",
       "Laurell K. Hamilton         6678  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_reviewed_books_author.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same but for the ebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>authors</th>\n",
       "      <th>not_helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>2</td>\n",
       "      <td>Minor New Jedi Order side story</td>\n",
       "      <td>0</td>\n",
       "      <td>With Ylesia, a novella originally published in...</td>\n",
       "      <td>Walter Jon Williams</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>5</td>\n",
       "      <td>Ylesia</td>\n",
       "      <td>0</td>\n",
       "      <td>Great book couldn't put it down.  The story ex...</td>\n",
       "      <td>Walter Jon Williams</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>4</td>\n",
       "      <td>A Thrackan story</td>\n",
       "      <td>2</td>\n",
       "      <td>Most of the New Jedi Order books focus on the ...</td>\n",
       "      <td>Walter Jon Williams</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>5</td>\n",
       "      <td>my e- collection</td>\n",
       "      <td>0</td>\n",
       "      <td>I was hoping to find this one in book form. Th...</td>\n",
       "      <td>Walter Jon Williams</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>B000FA64QO</td>\n",
       "      <td>3</td>\n",
       "      <td>One huge chapter</td>\n",
       "      <td>0</td>\n",
       "      <td>The events of \"Ylesia\" take place during \"Dest...</td>\n",
       "      <td>Walter Jon Williams</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        asin  overall                          summary  helpful  \\\n",
       "0          21  B000FA64QO        2  Minor New Jedi Order side story        0   \n",
       "1          22  B000FA64QO        5                           Ylesia        0   \n",
       "2          23  B000FA64QO        4                 A Thrackan story        2   \n",
       "3          24  B000FA64QO        5                 my e- collection        0   \n",
       "4          25  B000FA64QO        3                 One huge chapter        0   \n",
       "\n",
       "                                          reviewText              authors  \\\n",
       "0  With Ylesia, a novella originally published in...  Walter Jon Williams   \n",
       "1  Great book couldn't put it down.  The story ex...  Walter Jon Williams   \n",
       "2  Most of the New Jedi Order books focus on the ...  Walter Jon Williams   \n",
       "3  I was hoping to find this one in book form. Th...  Walter Jon Williams   \n",
       "4  The events of \"Ylesia\" take place during \"Dest...  Walter Jon Williams   \n",
       "\n",
       "   not_helpful  \n",
       "0            0  \n",
       "1            0  \n",
       "2            2  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_ebooksh = matched_ebooksh.dropna(subset=['authors_e']).rename(columns ={'authors_e':'authors'})\n",
    "matched_ebooksh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ebooks_review_per_author = matched_ebooksh.groupby('authors').agg('count')\n",
    "most_reviewed_ebooks_author = ebooks_review_per_author.sort_values('overall', ascending =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>not_helpful</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authors</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nicky Charles</th>\n",
       "      <td>2631</td>\n",
       "      <td>2631</td>\n",
       "      <td>2631</td>\n",
       "      <td>2631</td>\n",
       "      <td>2631</td>\n",
       "      <td>2631</td>\n",
       "      <td>2631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kristen Ashley</th>\n",
       "      <td>2104</td>\n",
       "      <td>2104</td>\n",
       "      <td>2104</td>\n",
       "      <td>2104</td>\n",
       "      <td>2104</td>\n",
       "      <td>2104</td>\n",
       "      <td>2104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Christopher Nuttall</th>\n",
       "      <td>1905</td>\n",
       "      <td>1905</td>\n",
       "      <td>1905</td>\n",
       "      <td>1905</td>\n",
       "      <td>1905</td>\n",
       "      <td>1905</td>\n",
       "      <td>1905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Elizabeth Lennox</th>\n",
       "      <td>1599</td>\n",
       "      <td>1599</td>\n",
       "      <td>1599</td>\n",
       "      <td>1599</td>\n",
       "      <td>1599</td>\n",
       "      <td>1599</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jasinda Wilder</th>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "      <td>1497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unnamed: 0  asin  overall  summary  helpful  reviewText  \\\n",
       "authors                                                                        \n",
       "Nicky Charles              2631  2631     2631     2631     2631        2631   \n",
       "Kristen Ashley             2104  2104     2104     2104     2104        2104   \n",
       "Christopher Nuttall        1905  1905     1905     1905     1905        1905   \n",
       "Elizabeth Lennox           1599  1599     1599     1599     1599        1599   \n",
       "Jasinda Wilder             1497  1497     1497     1497     1497        1497   \n",
       "\n",
       "                     not_helpful  \n",
       "authors                           \n",
       "Nicky Charles               2631  \n",
       "Kristen Ashley              2104  \n",
       "Christopher Nuttall         1905  \n",
       "Elizabeth Lennox            1599  \n",
       "Jasinda Wilder              1497  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_reviewed_ebooks_author.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we see? Nothing, we don't have the same authors in the two rankings, and the number of ratings is not even of the same magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     167\n",
       "asin           167\n",
       "overall        167\n",
       "summary        167\n",
       "helpful        167\n",
       "reviewText     167\n",
       "not_helpful    167\n",
       "Name: Stephen King, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebooks_review_per_author.loc['Stephen King']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_review_per_author = most_reviewed_books_author.merge(most_reviewed_ebooks_author,\n",
    "                                                          left_index=True, right_index=True,\n",
    "                                                         suffixes=('_book', '_ebook'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_books_authors = merged_review_per_author.head(20)[['overall_book','overall_ebook']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>authors</th>\n",
       "      <th>not_helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>268</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>5</td>\n",
       "      <td>Great</td>\n",
       "      <td>0</td>\n",
       "      <td>for getting your kid introduced to his/her ABC...</td>\n",
       "      <td>Stan Berenstain, Jan Berenstain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>3</td>\n",
       "      <td>A celebration of B</td>\n",
       "      <td>1</td>\n",
       "      <td>This Book is funny and is full of B words, lik...</td>\n",
       "      <td>Stan Berenstain, Jan Berenstain</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>270</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>5</td>\n",
       "      <td>Big B Believer</td>\n",
       "      <td>2</td>\n",
       "      <td>A favorite Berenstain book of my children I wa...</td>\n",
       "      <td>Stan Berenstain, Jan Berenstain</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>5</td>\n",
       "      <td>Very funny book, sad ending though!</td>\n",
       "      <td>0</td>\n",
       "      <td>This book is quite funny.  Especially when you...</td>\n",
       "      <td>Stan Berenstain, Jan Berenstain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>272</td>\n",
       "      <td>000171287X</td>\n",
       "      <td>5</td>\n",
       "      <td>Child's book</td>\n",
       "      <td>0</td>\n",
       "      <td>Teaching the next generation to love books!  M...</td>\n",
       "      <td>Stan Berenstain, Jan Berenstain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        asin  overall                              summary  \\\n",
       "0         268  000171287X        5                                Great   \n",
       "1         269  000171287X        3                   A celebration of B   \n",
       "2         270  000171287X        5                       Big B Believer   \n",
       "3         271  000171287X        5  Very funny book, sad ending though!   \n",
       "4         272  000171287X        5                         Child's book   \n",
       "\n",
       "   helpful                                         reviewText  \\\n",
       "0        0  for getting your kid introduced to his/her ABC...   \n",
       "1        1  This Book is funny and is full of B words, lik...   \n",
       "2        2  A favorite Berenstain book of my children I wa...   \n",
       "3        0  This book is quite funny.  Especially when you...   \n",
       "4        0  Teaching the next generation to love books!  M...   \n",
       "\n",
       "                           authors  not_helpful  \n",
       "0  Stan Berenstain, Jan Berenstain            0  \n",
       "1  Stan Berenstain, Jan Berenstain            3  \n",
       "2  Stan Berenstain, Jan Berenstain            2  \n",
       "3  Stan Berenstain, Jan Berenstain            0  \n",
       "4  Stan Berenstain, Jan Berenstain            0  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_booksh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Stephen King', 'Nora Roberts', 'Lee Child', 'H.M. Ward',\n",
       "       'David Baldacci', 'Michael Connelly', 'James Patterson', 'Dean Koontz',\n",
       "       'Abbi Glines', 'Debbie Macomber', 'Veronica Roth', 'Sylvia Day',\n",
       "       'J.R. Ward', 'Jessica Sorensen', 'Hugh Howey', 'Kristen Ashley',\n",
       "       'Marie Force', 'Orson Scott Card', 'Susan Mallery',\n",
       "       'Laurell K. Hamilton'],\n",
       "      dtype='object', name='authors')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_books_authors.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_books_top_authors = matched_booksh[matched_booksh['authors'].isin(top_books_authors.index)]\n",
    "match_ebooks_top_authors = matched_ebooksh[matched_ebooksh['authors'].isin(top_books_authors.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_authors_weighted_books_score = 'top_authors_weighted_books_score.csv'\n",
    "top_authors_weighted_kindle_score = 'top_authors_weighted_kindle_score.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Batch 1/10 of length 22333\n",
      "Batch 2/10 of length 19414\n",
      "Batch 3/10 of length 16350\n",
      "Batch 4/10 of length 25410\n",
      "Batch 5/10 of length 31881\n",
      "Batch 6/10 of length 25288\n",
      "Batch 7/10 of length 18897\n",
      "Batch 8/10 of length 15912\n",
      "Batch 9/10 of length 20596\n",
      "Batch 10/10 of length 18512\n"
     ]
    }
   ],
   "source": [
    "if WRITE_WEIGHTED_SCORE:\n",
    "    compute_by_batch(match_books_top_authors.set_index('authors'), 2, top_authors_weighted_books_score, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "Batch 1/1 of length 7307\n"
     ]
    }
   ],
   "source": [
    "if WRITE_WEIGHTED_SCORE:\n",
    "    compute_by_batch(match_ebooks_top_authors.set_index('authors'), 20, top_authors_weighted_kindle_score, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_authors_books_score = pd.read_csv(top_authors_weighted_books_score)\n",
    "top_authors_ebooks_score = pd.read_csv(top_authors_weighted_kindle_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>combined_score_book</th>\n",
       "      <th>combined_score_kindle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dean Koontz</td>\n",
       "      <td>3.836427</td>\n",
       "      <td>3.950129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James Patterson</td>\n",
       "      <td>3.773792</td>\n",
       "      <td>3.509067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Debbie Macomber</td>\n",
       "      <td>4.222705</td>\n",
       "      <td>4.118434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Veronica Roth</td>\n",
       "      <td>3.839826</td>\n",
       "      <td>4.039917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orson Scott Card</td>\n",
       "      <td>4.061193</td>\n",
       "      <td>4.306200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sylvia Day</td>\n",
       "      <td>4.038227</td>\n",
       "      <td>3.982908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Michael Connelly</td>\n",
       "      <td>3.989594</td>\n",
       "      <td>3.723958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lee Child</td>\n",
       "      <td>3.903025</td>\n",
       "      <td>4.565156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stephen King</td>\n",
       "      <td>4.024501</td>\n",
       "      <td>3.837746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hugh Howey</td>\n",
       "      <td>4.267384</td>\n",
       "      <td>4.165318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nora Roberts</td>\n",
       "      <td>4.150820</td>\n",
       "      <td>4.383331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Susan Mallery</td>\n",
       "      <td>4.322910</td>\n",
       "      <td>4.063838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>David Baldacci</td>\n",
       "      <td>4.032804</td>\n",
       "      <td>3.968965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Laurell K. Hamilton</td>\n",
       "      <td>3.340668</td>\n",
       "      <td>3.211626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>J.R. Ward</td>\n",
       "      <td>4.158237</td>\n",
       "      <td>4.438871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Marie Force</td>\n",
       "      <td>4.375588</td>\n",
       "      <td>4.374434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kristen Ashley</td>\n",
       "      <td>4.285780</td>\n",
       "      <td>4.282109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>H.M. Ward</td>\n",
       "      <td>4.246884</td>\n",
       "      <td>4.236060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Abbi Glines</td>\n",
       "      <td>4.311430</td>\n",
       "      <td>4.331367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jessica Sorensen</td>\n",
       "      <td>4.154628</td>\n",
       "      <td>4.060024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                authors  combined_score_book  combined_score_kindle\n",
       "0           Dean Koontz             3.836427               3.950129\n",
       "1       James Patterson             3.773792               3.509067\n",
       "2       Debbie Macomber             4.222705               4.118434\n",
       "3         Veronica Roth             3.839826               4.039917\n",
       "4      Orson Scott Card             4.061193               4.306200\n",
       "5            Sylvia Day             4.038227               3.982908\n",
       "6      Michael Connelly             3.989594               3.723958\n",
       "7             Lee Child             3.903025               4.565156\n",
       "8          Stephen King             4.024501               3.837746\n",
       "9            Hugh Howey             4.267384               4.165318\n",
       "10         Nora Roberts             4.150820               4.383331\n",
       "11        Susan Mallery             4.322910               4.063838\n",
       "12       David Baldacci             4.032804               3.968965\n",
       "13  Laurell K. Hamilton             3.340668               3.211626\n",
       "14            J.R. Ward             4.158237               4.438871\n",
       "15          Marie Force             4.375588               4.374434\n",
       "16       Kristen Ashley             4.285780               4.282109\n",
       "17            H.M. Ward             4.246884               4.236060\n",
       "18          Abbi Glines             4.311430               4.331367\n",
       "19     Jessica Sorensen             4.154628               4.060024"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_top_authors = top_authors_books_score[['authors', 'combined_score']].merge(\n",
    "    top_authors_ebooks_score[['authors', 'combined_score']], on='authors', suffixes=('_book', '_kindle'))\n",
    "scores_top_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "214593"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short_ebooks= pd.read_csv(matched_ebooks_short)\n",
    "short_books = pd.read_csv(matched_books_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "short_booksh = parse_help(short_books)\n",
    "short_ebooksh = parse_help(short_ebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>not_helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23406</td>\n",
       "      <td>0007269854</td>\n",
       "      <td>4</td>\n",
       "      <td>intriguing</td>\n",
       "      <td>A1A2YTFX2XC4O2</td>\n",
       "      <td>1</td>\n",
       "      <td>Scandinavian mysteries have a certain cool cha...</td>\n",
       "      <td>Aleksandra Nita-Lazar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23407</td>\n",
       "      <td>0007269854</td>\n",
       "      <td>4</td>\n",
       "      <td>Well done Scandanavian noir!</td>\n",
       "      <td>A1X2YRSD648FM3</td>\n",
       "      <td>1</td>\n",
       "      <td>Taut, well-written Scandanavian noir. Writer E...</td>\n",
       "      <td>Alexandra Henshel \"Librarian/Book Blogger/Pas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23408</td>\n",
       "      <td>0007269854</td>\n",
       "      <td>3</td>\n",
       "      <td>Suspense! and love!</td>\n",
       "      <td>AEMM6NOR4WJQE</td>\n",
       "      <td>0</td>\n",
       "      <td>I wrote this review for my blog, Little Miss R...</td>\n",
       "      <td>AmandaEmma @ Little Miss Reader</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23409</td>\n",
       "      <td>0007269854</td>\n",
       "      <td>4</td>\n",
       "      <td>Firt time reading Camilla Lackberg</td>\n",
       "      <td>A1BOGFPEV1FNB8</td>\n",
       "      <td>0</td>\n",
       "      <td>Living in Europe, I always wanted to read her ...</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23410</td>\n",
       "      <td>0007269854</td>\n",
       "      <td>3</td>\n",
       "      <td>Maybe the next one</td>\n",
       "      <td>A19145U1AEX74L</td>\n",
       "      <td>5</td>\n",
       "      <td>So many good Swedish crime writers these days ...</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        asin  overall                             summary  \\\n",
       "0       23406  0007269854        4                          intriguing   \n",
       "1       23407  0007269854        4        Well done Scandanavian noir!   \n",
       "2       23408  0007269854        3                 Suspense! and love!   \n",
       "3       23409  0007269854        4  Firt time reading Camilla Lackberg   \n",
       "4       23410  0007269854        3                  Maybe the next one   \n",
       "\n",
       "       reviewerID  helpful                                         reviewText  \\\n",
       "0  A1A2YTFX2XC4O2        1  Scandinavian mysteries have a certain cool cha...   \n",
       "1  A1X2YRSD648FM3        1  Taut, well-written Scandanavian noir. Writer E...   \n",
       "2   AEMM6NOR4WJQE        0  I wrote this review for my blog, Little Miss R...   \n",
       "3  A1BOGFPEV1FNB8        0  Living in Europe, I always wanted to read her ...   \n",
       "4  A19145U1AEX74L        5  So many good Swedish crime writers these days ...   \n",
       "\n",
       "                                       reviewerName  not_helpful  \n",
       "0                             Aleksandra Nita-Lazar            1  \n",
       "1  Alexandra Henshel \"Librarian/Book Blogger/Pas...            1  \n",
       "2                   AmandaEmma @ Little Miss Reader            0  \n",
       "3                                   Amazon Customer            0  \n",
       "4                                   Amazon Customer            5  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_booksh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1332"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(short_booksh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_books = sqlContext.createDataFrame(short_booksh.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ebooks = sqlContext.createDataFrame(short_ebooksh.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------+--------------------+--------------+-------+--------------------+--------------------+-----------+\n",
      "|Unnamed: 0|      asin|overall|             summary|    reviewerID|helpful|          reviewText|        reviewerName|not_helpful|\n",
      "+----------+----------+-------+--------------------+--------------+-------+--------------------+--------------------+-----------+\n",
      "|     23406|0007269854|      4|          intriguing|A1A2YTFX2XC4O2|      1|Scandinavian myst...|Aleksandra Nita-L...|          1|\n",
      "|     23407|0007269854|      4|Well done Scandan...|A1X2YRSD648FM3|      1|Taut, well-writte...|Alexandra Henshel...|          1|\n",
      "|     23408|0007269854|      3| Suspense! and love!| AEMM6NOR4WJQE|      0|I wrote this revi...|AmandaEmma @ Litt...|          0|\n",
      "|     23409|0007269854|      4|Firt time reading...|A1BOGFPEV1FNB8|      0|Living in Europe,...|     Amazon Customer|          0|\n",
      "|     23410|0007269854|      3|  Maybe the next one|A19145U1AEX74L|      5|So many good Swed...|     Amazon Customer|          5|\n",
      "|     23411|0007269854|      5|A fine, unexpecte...|A2M4R8R6SU049A|      2|Imagine that you ...|Amazon Customer \"...|          4|\n",
      "|     23412|0007269854|      4|Strong Atmospheri...|A2AFIEWV1QKF8E|      0|This is the first...|          Anne Mills|          0|\n",
      "|     23413|0007269854|      2|Just could not ge...|A2PEKLR1DGLY7L|      1|The description o...| a reader \"of books\"|          1|\n",
      "|     23414|0007269854|      4|        series debut| A2C27IQUH9N1Z|      0|Erica Falck, a bi...|              audrey|          0|\n",
      "|     23415|0007269854|      4|Good if you can o...|A3GO0DT9HL036A|      0|It was a good plo...|                  BA|          0|\n",
      "|     23416|0007269854|      2|         Predictable|A27UOBF7PW2RS7|      2|This book was rec...| Barbara C. Shanahan|          2|\n",
      "|     23417|0007269854|      1|Absurd police ine...|A38L3I3R3VRPTT|      0|I agree with the ...|Bay Area Biblioph...|          0|\n",
      "|     23418|0007269854|      5|     Truly a mystery|A362OHUN4V0ZKG|      0|The Ice Princess ...| B. Harding \"Bookie\"|          1|\n",
      "|     23419|0007269854|      3|It's always the q...| A9OU7Y9RJ120Q|      0|Fjallbacka, Swede...|      Bibliophagista|          0|\n",
      "|     23420|0007269854|      4|Slow burner rathe...| A8RC9GQ0Z4ASL|      1|Set in the small ...|          Big Bertha|          1|\n",
      "|     23421|0007269854|      3|    Good action read|A2L9TUOE290MT4|      0|A bit slow starti...|      Bill Thibadeau|          0|\n",
      "|     23422|0007269854|      5|Scandinavian dete...|A34YIIIRPAFLD5|      1|I was delighted t...|              Bizgen|          1|\n",
      "|     23423|0007269854|      4|Slow developing m...|A15YT5AKBDUGU0|      0|The story starts ...|                 Bob|          0|\n",
      "|     23424|0007269854|      4|I will read this ...|A2FIVHXR4MW403|      1|The Stone Cutter ...|                 Bob|          1|\n",
      "|     23425|0007269854|      3|baffled by the pr...| A2YEY2YJPDDY5|      2|Val McDermid rave...|             Bookbug|          2|\n",
      "+----------+----------+-------+--------------------+--------------+-------+--------------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_books.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_df = weighted_scores_spark(df_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>sentiment_review_score</th>\n",
       "      <th>sentiment_summary_score</th>\n",
       "      <th>sentiment_average_score</th>\n",
       "      <th>sentiment_rescaled</th>\n",
       "      <th>overall_score</th>\n",
       "      <th>combined_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1935053280</td>\n",
       "      <td>0.433350</td>\n",
       "      <td>0.118933</td>\n",
       "      <td>0.276142</td>\n",
       "      <td>3.552283</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.526142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1847530478</td>\n",
       "      <td>0.562950</td>\n",
       "      <td>0.301367</td>\n",
       "      <td>0.432158</td>\n",
       "      <td>3.864317</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4.348825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1573430080</td>\n",
       "      <td>0.995813</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>0.509053</td>\n",
       "      <td>4.018106</td>\n",
       "      <td>4.321325</td>\n",
       "      <td>4.169716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1482567288</td>\n",
       "      <td>0.369068</td>\n",
       "      <td>0.037933</td>\n",
       "      <td>0.203501</td>\n",
       "      <td>3.407002</td>\n",
       "      <td>4.280663</td>\n",
       "      <td>3.843832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0375700102</td>\n",
       "      <td>-0.152900</td>\n",
       "      <td>0.102067</td>\n",
       "      <td>-0.025417</td>\n",
       "      <td>2.949167</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.224583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0375840990</td>\n",
       "      <td>0.609310</td>\n",
       "      <td>0.285632</td>\n",
       "      <td>0.447471</td>\n",
       "      <td>3.894942</td>\n",
       "      <td>4.170732</td>\n",
       "      <td>4.032836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0758208863</td>\n",
       "      <td>0.882174</td>\n",
       "      <td>0.205977</td>\n",
       "      <td>0.544076</td>\n",
       "      <td>4.088151</td>\n",
       "      <td>2.902932</td>\n",
       "      <td>3.495542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1600431046</td>\n",
       "      <td>0.961020</td>\n",
       "      <td>0.229160</td>\n",
       "      <td>0.595090</td>\n",
       "      <td>4.190180</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.895090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>030788922X</td>\n",
       "      <td>0.882010</td>\n",
       "      <td>0.430938</td>\n",
       "      <td>0.656474</td>\n",
       "      <td>4.312947</td>\n",
       "      <td>4.659259</td>\n",
       "      <td>4.486104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>054521825X</td>\n",
       "      <td>0.434533</td>\n",
       "      <td>-0.358700</td>\n",
       "      <td>0.037917</td>\n",
       "      <td>3.075833</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.371250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin  sentiment_review_score  sentiment_summary_score  \\\n",
       "0  1935053280                0.433350                 0.118933   \n",
       "1  1847530478                0.562950                 0.301367   \n",
       "2  1573430080                0.995813                 0.022293   \n",
       "3  1482567288                0.369068                 0.037933   \n",
       "4  0375700102               -0.152900                 0.102067   \n",
       "5  0375840990                0.609310                 0.285632   \n",
       "6  0758208863                0.882174                 0.205977   \n",
       "7  1600431046                0.961020                 0.229160   \n",
       "8  030788922X                0.882010                 0.430938   \n",
       "9  054521825X                0.434533                -0.358700   \n",
       "\n",
       "   sentiment_average_score  sentiment_rescaled  overall_score  combined_score  \n",
       "0                 0.276142            3.552283       3.500000        3.526142  \n",
       "1                 0.432158            3.864317       4.833333        4.348825  \n",
       "2                 0.509053            4.018106       4.321325        4.169716  \n",
       "3                 0.203501            3.407002       4.280663        3.843832  \n",
       "4                -0.025417            2.949167       3.500000        3.224583  \n",
       "5                 0.447471            3.894942       4.170732        4.032836  \n",
       "6                 0.544076            4.088151       2.902932        3.495542  \n",
       "7                 0.595090            4.190180       3.600000        3.895090  \n",
       "8                 0.656474            4.312947       4.659259        4.486104  \n",
       "9                 0.037917            3.075833       3.666667        3.371250  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_review_score     0.433350\n",
       "sentiment_summary_score    0.118933\n",
       "sentiment_average_score    0.276142\n",
       "sentiment_rescaled         3.552283\n",
       "overall_score              3.500000\n",
       "combined_score             3.526142\n",
       "Name: 1935053280, dtype: float64"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_scores_books.set_index('asin').loc['1935053280']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if WRITE_WEIGHTED_SCORE:\n",
    "    weighted_scores_books = weighted_scores(matched_books.copy())\n",
    "    weighted_scores_ebooks = weighted_scores(matched_ebooks.copy())\n",
    "\n",
    "    weighted_scores_books.to_csv(weighted_scores_books_path)\n",
    "    weighted_scores_ebooks.to_csv(weighted_scores_ebooks_path)\n",
    "\n",
    "weighted_scores_books = pd.read_csv(weighted_scores_books_path)\n",
    "weighted_scores_ebooks = pd.read_csv(weighted_scores_ebooks_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have computed the different scores for the books and the ebooks, it is now time to combine those scores with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_metadatas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4353d89f0c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerged_with_books\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_metadatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_scores_books\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'asin_book'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'asin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmerged_with_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_with_books\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_scores_ebooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'asin_ebook'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'asin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_book'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_ebook'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'merged_metadatas' is not defined"
     ]
    }
   ],
   "source": [
    "merged_with_books = pd.merge(merged_metadatas, weighted_scores_books, left_on='asin_book', right_on='asin')\n",
    "merged_with_all = pd.merge(merged_with_books, weighted_scores_ebooks, left_on='asin_ebook', right_on='asin', suffixes=['_book', '_ebook'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>combined_score_book</th>\n",
       "      <th>combined_score_ebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the ice princess</td>\n",
       "      <td>3.587650</td>\n",
       "      <td>4.257872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the sweetest taboo</td>\n",
       "      <td>3.931882</td>\n",
       "      <td>4.498829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dragons from the sea (the strongbow saga, book 2)</td>\n",
       "      <td>4.250450</td>\n",
       "      <td>4.272470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iced</td>\n",
       "      <td>4.293400</td>\n",
       "      <td>4.010218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>made in italy</td>\n",
       "      <td>4.486103</td>\n",
       "      <td>4.065768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  combined_score_book  \\\n",
       "0                                   the ice princess             3.587650   \n",
       "1                                 the sweetest taboo             3.931882   \n",
       "2  dragons from the sea (the strongbow saga, book 2)             4.250450   \n",
       "3                                               iced             4.293400   \n",
       "4                                      made in italy             4.486103   \n",
       "\n",
       "   combined_score_ebook  \n",
       "0              4.257872  \n",
       "1              4.498829  \n",
       "2              4.272470  \n",
       "3              4.010218  \n",
       "4              4.065768  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_with_all[['title', 'combined_score_book', 'combined_score_ebook']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_with_all.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "combined_score_book     4.048685\n",
       "combined_score_ebook    4.107403\n",
       "dtype: float64"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_combined_score = merged_with_all[['combined_score_book', 'combined_score_ebook']].mean()\n",
    "average_combined_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_average_score_book     0.453672\n",
       "sentiment_average_score_ebook    0.460862\n",
       "dtype: float64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_sentiment_score = merged_with_all[['sentiment_average_score_book', 'sentiment_average_score_ebook']].mean()\n",
    "average_sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall_score_book     4.190025\n",
       "overall_score_ebook    4.293082\n",
       "dtype: float64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_overall_score = merged_with_all[['overall_score_book', 'overall_score_ebook']].mean()\n",
    "average_overall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to see if the sentiment's score is consistent with the ratings, meaning that reviewers giving high ratings should also be positive in their reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_review_spark(data):\n",
    "    func = udf(lambda x: sid.polarity_scores(x)['compound'], T.DoubleType())\n",
    "    \n",
    "    data = data.withColumn('sentiment_review', func('reviewText'))\n",
    "    data = data.withColumn('sentiment_summary', func('summary'))\n",
    "    data = data.withColumn('average', average('sentiment_review', 'sentiment_summary'))\n",
    "    \n",
    "    output = data.groupby('overall').mean()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_books_spark = compute_review_spark(df_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+----------------------+-------------------+\n",
      "|overall|avg(sentiment_review)|avg(sentiment_summary)|       avg(average)|\n",
      "+-------+---------------------+----------------------+-------------------+\n",
      "|      1|   0.2132704918032787|   -0.1750393442622951| 0.0191155754060286|\n",
      "|      2|  0.25019729729729734|  -0.09078108108108109| 0.0797081066396188|\n",
      "|      3|  0.45108508287292826|   0.12167734806629835|0.28638121544110756|\n",
      "|      4|   0.6750380368098159|    0.2766843558282209| 0.4758611955577108|\n",
      "|      5|   0.7279273913043477|   0.35499362318840577| 0.5414605070198667|\n",
      "+-------+---------------------+----------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_books_spark.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+----------------------+--------------------+\n",
      "|overall|avg(sentiment_review)|avg(sentiment_summary)|        avg(average)|\n",
      "+-------+---------------------+----------------------+--------------------+\n",
      "|      1| -0.17026734693877552|   -0.1285469387755102|-0.14940714349552076|\n",
      "|      2|  0.04509636363636363|  -0.07638818181818183|-0.01564590912312...|\n",
      "|      3|   0.5050530303030303|   0.17854356060606064| 0.34179829636758025|\n",
      "|      4|   0.6634223342939483|   0.26759639769452453| 0.46550936567709816|\n",
      "|      5|   0.6896207233626589|   0.35525992179863136|  0.5224403232565461|\n",
      "+-------+---------------------+----------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_ebooks_spark = compute_review_spark(df_ebooks)\n",
    "reviews_ebooks_spark.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_books_with_sentiment = matched_books.copy()\n",
    "f_sentiment = lambda x: sid.polarity_scores(x)['compound']\n",
    "reviews_books_with_sentiment['sentiment_review'] = matched_books['reviewText'].apply(f_sentiment)\n",
    "reviews_books_with_sentiment['sentiment_summary'] = matched_books['summary'].apply(f_sentiment)\n",
    "reviews_books_with_sentiment['average'] = (reviews_books_with_sentiment['sentiment_review'] + reviews_books_with_sentiment['sentiment_summary'])*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentiment_review</th>\n",
       "      <th>sentiment_summary</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.683335e+06</td>\n",
       "      <td>0.213270</td>\n",
       "      <td>-0.175039</td>\n",
       "      <td>0.019116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.191242e+06</td>\n",
       "      <td>0.250197</td>\n",
       "      <td>-0.090781</td>\n",
       "      <td>0.079708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.451677e+06</td>\n",
       "      <td>0.451085</td>\n",
       "      <td>0.121677</td>\n",
       "      <td>0.286381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.435581e+06</td>\n",
       "      <td>0.675038</td>\n",
       "      <td>0.276684</td>\n",
       "      <td>0.475861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.741658e+06</td>\n",
       "      <td>0.727927</td>\n",
       "      <td>0.354994</td>\n",
       "      <td>0.541461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0  sentiment_review  sentiment_summary   average\n",
       "overall                                                             \n",
       "1        3.683335e+06          0.213270          -0.175039  0.019116\n",
       "2        3.191242e+06          0.250197          -0.090781  0.079708\n",
       "3        3.451677e+06          0.451085           0.121677  0.286381\n",
       "4        3.435581e+06          0.675038           0.276684  0.475861\n",
       "5        3.741658e+06          0.727927           0.354994  0.541461"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_books_with_sentiment.groupby('overall').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>sentiment_review</th>\n",
       "      <th>sentiment_summary</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23417</td>\n",
       "      <td>0007269854</td>\n",
       "      <td>1</td>\n",
       "      <td>Absurd police ineptitude</td>\n",
       "      <td>A38L3I3R3VRPTT</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I agree with the complaints about cliches, car...</td>\n",
       "      <td>Bay Area Bibliophile \"marisylvia\"</td>\n",
       "      <td>0.6467</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.32335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>23470</td>\n",
       "      <td>0007269854</td>\n",
       "      <td>1</td>\n",
       "      <td>Hated it</td>\n",
       "      <td>A2T1ZGMIFSHWW2</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>Giving up at pg 139 (of 389, paperback). I no ...</td>\n",
       "      <td>In Vino Veritas</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>-0.6369</td>\n",
       "      <td>0.08785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>23471</td>\n",
       "      <td>0007269854</td>\n",
       "      <td>1</td>\n",
       "      <td>Not so good</td>\n",
       "      <td>A23J25BQYRAIVX</td>\n",
       "      <td>[13, 15]</td>\n",
       "      <td>If you're a fan of Scandinavian crime fiction,...</td>\n",
       "      <td>Jack Tierney</td>\n",
       "      <td>-0.9862</td>\n",
       "      <td>-0.3865</td>\n",
       "      <td>-0.68635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>23473</td>\n",
       "      <td>0007269854</td>\n",
       "      <td>1</td>\n",
       "      <td>Audiobook CDs poor grade</td>\n",
       "      <td>A3UYDNMNB7VX75</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>My complaint is not with the novel, but with t...</td>\n",
       "      <td>Jane F. Wiedel \"dog lover\"</td>\n",
       "      <td>-0.9821</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>-0.72940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>23506</td>\n",
       "      <td>0007269854</td>\n",
       "      <td>1</td>\n",
       "      <td>I don't usually write bad reviews.</td>\n",
       "      <td>A3RIGC6OUSKQ8R</td>\n",
       "      <td>[6, 6]</td>\n",
       "      <td>However, I am 78 pages into this book and I ma...</td>\n",
       "      <td>Mary Ann Moore</td>\n",
       "      <td>-0.7228</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>-0.14590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        asin  overall                             summary  \\\n",
       "11        23417  0007269854        1            Absurd police ineptitude   \n",
       "64        23470  0007269854        1                            Hated it   \n",
       "65        23471  0007269854        1                         Not so good   \n",
       "67        23473  0007269854        1            Audiobook CDs poor grade   \n",
       "100       23506  0007269854        1  I don't usually write bad reviews.   \n",
       "\n",
       "         reviewerID   helpful  \\\n",
       "11   A38L3I3R3VRPTT    [0, 0]   \n",
       "64   A2T1ZGMIFSHWW2    [5, 5]   \n",
       "65   A23J25BQYRAIVX  [13, 15]   \n",
       "67   A3UYDNMNB7VX75    [0, 0]   \n",
       "100  A3RIGC6OUSKQ8R    [6, 6]   \n",
       "\n",
       "                                            reviewText  \\\n",
       "11   I agree with the complaints about cliches, car...   \n",
       "64   Giving up at pg 139 (of 389, paperback). I no ...   \n",
       "65   If you're a fan of Scandinavian crime fiction,...   \n",
       "67   My complaint is not with the novel, but with t...   \n",
       "100  However, I am 78 pages into this book and I ma...   \n",
       "\n",
       "                          reviewerName  sentiment_review  sentiment_summary  \\\n",
       "11   Bay Area Bibliophile \"marisylvia\"            0.6467             0.0000   \n",
       "64                     In Vino Veritas            0.8126            -0.6369   \n",
       "65                        Jack Tierney           -0.9862            -0.3865   \n",
       "67          Jane F. Wiedel \"dog lover\"           -0.9821            -0.4767   \n",
       "100                     Mary Ann Moore           -0.7228             0.4310   \n",
       "\n",
       "     average  \n",
       "11   0.32335  \n",
       "64   0.08785  \n",
       "65  -0.68635  \n",
       "67  -0.72940  \n",
       "100 -0.14590  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_books_with_sentiment[reviews_books_with_sentiment['overall'] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This book is just plain horrible and for me to say that is saying a lot.  I read everything and a Danielle Steel or Nora Roberts novel is like Shakespeare compared to this book.  I picked this book up because I loved Michael Chriton's Timeline so much.  I am facinated with the medieval ages and think the concept of someone from today's time comming in contact with the past is an intresting concept.  Unfortunately this book is not intresting in the least.  I went into the book really wanting to like it but the writing is so stiff and awkard.  The dialogue is not believable in the least.  The romance between Edward and Robyn which should be the focal point of the book is boring.  Edward is like a Ken doll, looks cute but is plastic with no personality.  I guess it doesn't matter in the end because he is not around for most of the story anyway.  If you read this book thinking you will learn something about the medieval ages you will be sorely dissappointed.  Edward doesn't talk like he's really from the medieval ages when he meets Robyn because it's a spell.  How convienent. The author didn't want to do in depth historical research so he uses spells to just explain everything away. I can't believe there are going to be two more books after this one.  If you want to read a wonderful book about the present meeting the medieval past get Timeline.  There is more action, romance, and historical accuracy in Time Line than you will ever find in Knight Errant.\""
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_books_with_sentiment.iloc[212]['reviewText']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This review above has a really positive sentiment score of 0.9735, but if we read the review, we can understand that it is quite the opposite. A second example is \"Not so good\" which yields a score of 0.4927, showing us the limitation of Vader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe here that the better the rating is, the more positive the text of the review is in average. The reviews with a rating of 1 are not negative in average. Even if the scores are not always accurate due to the limitation of Vader, they are consistent in average with the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_ebooks_with_sentiment = matched_ebooks.copy()\n",
    "reviews_ebooks_with_sentiment['sentiment_review'] = matched_ebooks['reviewText'].apply(f_sentiment)\n",
    "reviews_ebooks_with_sentiment['sentiment_summary'] = matched_ebooks['summary'].apply(f_sentiment)\n",
    "reviews_ebooks_with_sentiment['average'] = (reviews_ebooks_with_sentiment['sentiment_review'] + reviews_ebooks_with_sentiment['sentiment_summary'])*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentiment_review</th>\n",
       "      <th>sentiment_summary</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23266.285714</td>\n",
       "      <td>-0.170267</td>\n",
       "      <td>-0.128547</td>\n",
       "      <td>-0.149407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28643.590909</td>\n",
       "      <td>0.045096</td>\n",
       "      <td>-0.076388</td>\n",
       "      <td>-0.015646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28790.469697</td>\n",
       "      <td>0.505053</td>\n",
       "      <td>0.178544</td>\n",
       "      <td>0.341798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29388.108069</td>\n",
       "      <td>0.663422</td>\n",
       "      <td>0.267596</td>\n",
       "      <td>0.465509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27860.713587</td>\n",
       "      <td>0.689621</td>\n",
       "      <td>0.355260</td>\n",
       "      <td>0.522440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Unnamed: 0  sentiment_review  sentiment_summary   average\n",
       "overall                                                             \n",
       "1        23266.285714         -0.170267          -0.128547 -0.149407\n",
       "2        28643.590909          0.045096          -0.076388 -0.015646\n",
       "3        28790.469697          0.505053           0.178544  0.341798\n",
       "4        29388.108069          0.663422           0.267596  0.465509\n",
       "5        27860.713587          0.689621           0.355260  0.522440"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_ebooks_with_sentiment.groupby('overall').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratings seem to be consistent with the sentiment's score here again. Compared to books, the sentiment's score is slightly lower and even negative for a rating of 1.\n",
    "\n",
    "For the same rating, the books reviewer seems to be more positive in their review, this may be explained by the fact that books reviews tend to be longer and more descriptive than ebooks reviews.\n",
    "\n",
    "This analysis may not be really representative of the reality due to the limitation in size of our final dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "* *Improving the Amazon Review System by Exploiting the Credibility and Time-Decay of Public Reviews*, Bo-Chun Wang, Wen-Yuan Zhu, and Ling-Jyh Chen\n",
    "* Hutto, C.J. & Gilbert, E.E. (2014). *VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14)*. Ann Arbor, MI, June 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
