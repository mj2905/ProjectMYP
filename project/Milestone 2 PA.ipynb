{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Books versus eBooks : The customer's choice\n",
    "\n",
    "For the same content, which format seems to be prefered by people, based on Amazon reviews ?\n",
    "\n",
    "What is the price difference between the two supports, globally and per book category ?\n",
    "\n",
    "Per region, what is the favorite format between virtual and physical ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from ast import literal_eval\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata_path = 'data/metadata.json'\n",
    "books_metadata_path = 'data/books_metadata_with_bracket.csv'\n",
    "ebooks_metadata_title_path = 'data/ebooks_metadata_title.csv'\n",
    "ebooks_asin = 'data/ebooks_asin.csv'\n",
    "kindle_5core = 'data/reviews_Kindle_Store_5.json'\n",
    "books_path = 'data/Books_5.json'\n",
    "amazon_ebooks = 'data/ebooks_title_from_amazon_complete.csv'\n",
    "asindb_ebooks = 'data/ebooks_title_from_asindb.csv'\n",
    "\n",
    "matched_books_path = 'test/matched_books.csv'\n",
    "matched_ebooks_path = 'test/matched_ebooks.csv'\n",
    "weighted_scores_books_path = 'test/weighted_scores_books.csv'\n",
    "weighted_scores_ebooks_path = 'test/weighted_scores_ebooks.csv'\n",
    "\n",
    "\n",
    "WRITE_BOOKS_METADATA = False\n",
    "WRITE_EBOOKS_METADATA_TITLE = False\n",
    "WRITE_EBOOK_ASIN = False\n",
    "AMAZON_GET_TITLE = False\n",
    "ASINDB_GET_TITLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for our project, we need to obtain ebook data and book data, we chose the Amazon dataset. On this <a href='http://jmcauley.ucsd.edu/data/amazon/'>link</a>, we have downloaded the Books and Kindle Store 5-core files. However, those files contain reviews, so that we have no information about the article title or price.\n",
    "For that reason, we had to use the metadata file, acting as an intermediate table (relationship).\n",
    "\n",
    "TODO : how we obtained it from the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a json file, that is not readable using the pandas read_json method. We had to use the Code part from <a href='http://jmcauley.ucsd.edu/data/amazon/'>here</a> to read it. We can see a way to read the file (a limited portion of it) below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>imUrl</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001048791</td>\n",
       "      <td>{'Books': 6334800}</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51MKP0T4...</td>\n",
       "      <td>[[Books]]</td>\n",
       "      <td>The Crucible: Performed by Stuart Pankin, Jero...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000143561</td>\n",
       "      <td>{'Movies &amp; TV': 376041}</td>\n",
       "      <td>http://g-ecx.images-amazon.com/images/G/01/x-s...</td>\n",
       "      <td>[[Movies &amp; TV, Movies]]</td>\n",
       "      <td>Everyday Italian (with Giada de Laurentiis), V...</td>\n",
       "      <td>3Pack DVD set - Italian Classics, Parties and ...</td>\n",
       "      <td>12.99</td>\n",
       "      <td>{'also_viewed': ['B0036FO6SI', 'B000KL8ODE', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                salesRank  \\\n",
       "0  0001048791       {'Books': 6334800}   \n",
       "1  0000143561  {'Movies & TV': 376041}   \n",
       "\n",
       "                                               imUrl               categories  \\\n",
       "0  http://ecx.images-amazon.com/images/I/51MKP0T4...                [[Books]]   \n",
       "1  http://g-ecx.images-amazon.com/images/G/01/x-s...  [[Movies & TV, Movies]]   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Crucible: Performed by Stuart Pankin, Jero...   \n",
       "1  Everyday Italian (with Giada de Laurentiis), V...   \n",
       "\n",
       "                                         description  price  \\\n",
       "0                                                NaN    NaN   \n",
       "1  3Pack DVD set - Italian Classics, Parties and ...  12.99   \n",
       "\n",
       "                                             related  \n",
       "0                                                NaN  \n",
       "1  {'also_viewed': ['B0036FO6SI', 'B000KL8ODE', '...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_json(path, limit = 2): \n",
    "    g = open(path, 'r') \n",
    "    df = {}\n",
    "    for i, l in enumerate(g): \n",
    "        if i < limit:\n",
    "            df[i] = eval(l)\n",
    "        else:\n",
    "            break\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "def read_csv(path, limit = 2): \n",
    "    return pd.read_csv(path, nrows=limit)\n",
    "            \n",
    "read_json(metadata_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this metadata.json file takes more than 10 Go, for 9430088 entries (obtained by doing a wc -l metadata.json), so it does not fit in memory. Thus, as we will do a lot of tests later, we wanted to create a subfile containing only the Books metadata (we don't need video games metadata for example), with a subset of columns. We also want to write it in the csv format, to manipulate it in an easier way later.\n",
    "\n",
    "We use the regex \"\\[\\'books\" in an ignore case mode, to obtain only entries that have a category tag beginning with [Books. In fact, if we want to use the regex 'book', some entries like 0078800242 or B00000078S are not books at all, even if there is Books in the title or the category tag. The '[' is useful here to avoir this behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_book_metadata(path, regex): \n",
    "    g = open(path, 'r') \n",
    "    for l in g: \n",
    "        book = regex.search(l)\n",
    "        if book:\n",
    "            yield eval(l) \n",
    "            \n",
    "def write_df_books_metadata(from_, to, regex, columns_to_keep): \n",
    "    i = 0 \n",
    "    df = {} \n",
    "    for d in read_book_metadata(from_, regex): \n",
    "        df[i] = d \n",
    "        i += 1 \n",
    "        if i % 10000 == 0: # Here, we choose to write everything every 10'000 book entries, and clear the dataframe to free memory.\n",
    "            pd.DataFrame.from_dict(df, orient='index')[columns_to_keep].to_csv(to, header=False,mode='a')\n",
    "            df = {}\n",
    "\n",
    "COLUMNS_TO_KEEP = ['asin', 'salesRank', 'categories', 'title', 'price']\n",
    "regex = re.compile('\\[\\'books', re.IGNORECASE)\n",
    "\n",
    "if WRITE_BOOKS_METADATA:\n",
    "    pd.DataFrame(columns=[COLUMNS_TO_KEEP]).to_csv(books_metadata_path)\n",
    "    write_df_books_metadata(metadata_path, books_metadata_path, regex, COLUMNS_TO_KEEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we read what we just wrote :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1048791</td>\n",
       "      <td>{'Books': 6334800}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Crucible: Performed by Stuart Pankin, Jero...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1048775</td>\n",
       "      <td>{'Books': 13243226}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Measure for Measure: Complete &amp;amp; Unabridged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     asin            salesRank   categories  \\\n",
       "0           0  1048791   {'Books': 6334800}  [['Books']]   \n",
       "1           1  1048775  {'Books': 13243226}  [['Books']]   \n",
       "\n",
       "                                               title  price  \n",
       "0  The Crucible: Performed by Stuart Pankin, Jero...    NaN  \n",
       "1     Measure for Measure: Complete &amp; Unabridged    NaN  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_csv(books_metadata_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wanted to obtain the ebooks titles, price etc..\n",
    "For the category filter, we have to use the same trick as for the Books one : \"\\[\\'Kindle\". Please note that some book metadatas above are in fact kindle store metadatas, because the category can contain both. However, it's not a big deal if we want to do the merge later with asin column.\n",
    "\n",
    "However, for the metadatas for ebooks, there was a problem at that step :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ebooks in metadatas: 434702\n"
     ]
    }
   ],
   "source": [
    "def read_ebook_metadata(path, regex): \n",
    "    g = open(path, 'r') \n",
    "    for l in g: \n",
    "        ebook = regex.search(l)\n",
    "        if ebook:\n",
    "            yield eval(l) \n",
    "def obtain_df_ebooks_metadata(from_, to, regex): \n",
    "    i = 0 \n",
    "    df = {} \n",
    "    count = 0\n",
    "    for d in read_ebook_metadata(from_, regex): \n",
    "        count += 1\n",
    "        if(d.get('title')):\n",
    "            df[i] = {'asin': d.get('asin'), 'title': d.get('title')}\n",
    "            i += 1 \n",
    "    pd.DataFrame.from_dict(df, orient='index').to_csv(to)\n",
    "    print('Total ebooks in metadatas:', count)\n",
    "\n",
    "\n",
    "regex = re.compile('\\[\\'Kindle', re.IGNORECASE)\n",
    "\n",
    "if WRITE_EBOOKS_METADATA_TITLE:\n",
    "    obtain_df_ebooks_metadata(metadata_path, ebooks_metadata_title_path, regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see right below that 44 entries out of 434702 have a title. Of course, it's not good at all, since we want to merge books and ebooks using the title field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_csv(ebooks_metadata_title_path, None).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we need to obtain the title field from another source. The first idea was to retrieve this information from Amazon directly, as we wanted to do for the user location. For that, we need to have a list of the ebooks asin (Amazon Standard Identification Numbers). We obtain it from the Kindle Store 5-core file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n"
     ]
    }
   ],
   "source": [
    "def read_ebook_5core(path, regex): \n",
    "    g = open(path, 'r') \n",
    "    for l in g: \n",
    "        yield eval(l) \n",
    "def write_ebook_asin(from_, to): \n",
    "    i = 0 \n",
    "    df = {} \n",
    "    for d in read_ebook_5core(from_, regex): \n",
    "        df[i] = d \n",
    "        i += 1 \n",
    "        if i % 10000 == 0:\n",
    "            if i % 100000 == 0:\n",
    "                print(i) #to show the progression\n",
    "            pd.DataFrame.from_dict(df, orient='index')[['asin']].to_csv(to, header=False,mode='a')\n",
    "            df = {}\n",
    "    pd.DataFrame.from_dict(df, orient='index')[['asin']].to_csv(to, header=False,mode='a')\n",
    "    df = {}\n",
    "\n",
    "if WRITE_EBOOK_ASIN:\n",
    "    pd.DataFrame(columns=[['asin']]).to_csv(ebooks_asin)\n",
    "    write_ebook_asin(kindle_5core, ebooks_asin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we were using the Kindle Store 5-core file, there are asin duplicates. We thus make it unique when we read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B000F83SZQ', 'B000FA64PA', 'B000FA64PK', ..., 'B00M029T4O',\n",
       "       'B00M0RE7CS', 'B00M13FNSS'], dtype=object)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebooks_asin_unique = pd.read_csv('ebooks_asin.csv',usecols=[1]).asin.unique()\n",
    "ebooks_asin_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every Amazon article with asin *xasinx*, the corresponding web page is https://www.amazon.com/dp/*xasinx*/ref=rdr_kindle_ext_tmb.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = 'https://www.amazon.com/dp/'\n",
    "suffix = '/ref=rdr_kindle_ext_tmb'\n",
    "\n",
    "USER_AGENT_CHOICES = [\n",
    "    'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:23.0) Gecko/20100101 Firefox/23.0',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.62 Safari/537.36',\n",
    "    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; WOW64; Trident/6.0)',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.146 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/33.0.1750.146 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20140205 Firefox/24.0 Iceweasel/24.3.0',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; WOW64; rv:28.0) Gecko/20100101 Firefox/28.0',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; WOW64; rv:28.0) AppleWebKit/534.57.2 (KHTML, like Gecko) Version/5.1.7 Safari/534.57.2',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to rotate the user-agent so that the bot is less likely to be considered as one. This is why we have a User-Agent array.\n",
    "At the beginning, this method was working quite well : we had obtained 503 tuples (title, category, page number, language) over 1000 requests, which could mean that we had solved the problem. However, when looking at the distribution of the 503 tuples, we could see that at the beginning, everything behaves well, we obtain most of the entries (the other ones being like the B000JMKU0Y one, an obsolete entry, that only has customer reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "if AMAZON_GET_TITLE:\n",
    "    \n",
    "    LIMIT = 10\n",
    "    \n",
    "    undefined = 0\n",
    "    defined = 0\n",
    "    dataframe_original = pd.DataFrame(columns=[['asin', 'title', 'Category', 'PageNum', 'Language']])\n",
    "    dataframe = dataframe_original.copy()\n",
    "\n",
    "    dataframe_original.to_csv(amazon_ebooks)\n",
    "\n",
    "    for i, asin in enumerate(ebooks_asin_unique[:LIMIT]):\n",
    "\n",
    "        if i%10==0:\n",
    "            headers = {'User-Agent':USER_AGENT_CHOICES[np.random.randint(0, len(USER_AGENT_CHOICES))]}\n",
    "            if i > 0:\n",
    "                print('undefined:', undefined, '/ defined:', defined)\n",
    "                dataframe.to_csv(amazon_ebooks, header=False,mode='a')\n",
    "                dataframe = dataframe_original.copy()\n",
    "\n",
    "\n",
    "        r = requests.get(prefix + asin + suffix, headers=headers)\n",
    "        page_body = r.text\n",
    "        soup = BeautifulSoup(page_body, 'html.parser')\n",
    "        title = soup.find_all('span', id='ebooksProductTitle')\n",
    "        if(len(title) == 0):\n",
    "            undefined += 1\n",
    "        else:\n",
    "            defined += 1\n",
    "            title = title[0].text\n",
    "\n",
    "            ul = soup.find_all('ul', class_='a-unordered-list a-horizontal a-size-small')\n",
    "            if(len(ul) > 0):\n",
    "                details = ul[0].find_all('a', class_='a-link-normal a-color-tertiary')\n",
    "                if(len(details) > 0):\n",
    "                    category = details[-1].text.strip()\n",
    "                else:\n",
    "                    category = \"\"\n",
    "            else:\n",
    "                category = \"\"\n",
    "\n",
    "            details = soup.find_all('table', id='productDetailsTable')\n",
    "            if(len(details) > 0):\n",
    "                length = details[0].find_all('b', text='Print Length:')\n",
    "                if(len(length) > 0):\n",
    "                    page_number = length[0].parent.text.split()[2]\n",
    "                else:\n",
    "                    page_number = 0\n",
    "\n",
    "                length = details[0].find_all('b', text='Language:')\n",
    "                if(len(length) > 0):\n",
    "                    language = length[0].parent.text.split()[1]\n",
    "                else:\n",
    "                    language = \"\"\n",
    "            else:\n",
    "                page_number = pd.np.nan\n",
    "                language = \"\"\n",
    "\n",
    "            dataframe.loc[asin] = (asin, title, category, page_number, language)\n",
    "\n",
    "        waiting = np.random.rand()\n",
    "        time.sleep(waiting+1)\n",
    "\n",
    "    print(defined,',',undefined)\n",
    "    dataframe.to_csv(amazon_ebooks, header=False,mode='a')\n",
    "    dataframe = dataframe_original.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But after some time, we get less and less entries : a message is sent by Amazon when retrieving the page, saying that it's not a good idea to continue scraping data, and that it might be a good idea to go through their API. So, there were some options :\n",
    "- we continue to work with the bot while tweaking the parameters to behave like a normal user for the bot (by increasing the waiting time and rotating the user-agent as said before) :\n",
    "\n",
    "After some online search (https://www.scrapehero.com/how-to-prevent-getting-blacklisted-while-scraping/,\n",
    "http://blog.datahut.co/tutorial-how-to-scrape-amazon-using-python-scrapy/,\n",
    "http://docs.aws.amazon.com/AWSECommerceService/latest/DG/rest-signature.html,\n",
    "https://www.scrapehero.com/tutorial-how-to-scrape-amazon-product-details-using-python/,\n",
    "https://blog.hartleybrody.com/scrape-amazon/), we saw that Amazon was detecting the IP, it could ban it, and the solution to avoid it was to use a proxy crawler. As it costs money, we decided not to use that. Furthermore, as said here, it's a legally speaking grey area : https://benbernardblog.com/web-scraping-and-crawling-are-perfectly-legal-right/.\n",
    "\n",
    "- we try to go through the Amazon API : \n",
    "\n",
    "For the standard account, we need to put bank account information, so we prefer not to do so. For the student account, as we realized some days before the deadline that it existed, we might consider this option in the future if needed, but we wait for the epfl to accept or not the account request.\n",
    "\n",
    "- we find a field in the metadata, different from the title, that can help us to merge a book with an ebook :\n",
    "\n",
    "With some manual analysis, we found a pair of book-ebook : \n",
    "\n",
    "    {'asin': 'B000JML1QG', 'price': 0.99, 'imUrl': 'http://ecx.images-amazon.com/images/I/41VbZ%2BvxslL._BO2,204,203,200_PIsitb-sticker-v3-big,TopRight,0,-55_SX278_SY278_PIkin4,BottomRight,1,22_AA300_SH20_OU01_.jpg', 'related': {'also_viewed': ['B005LSCQ4Y', 'B0082UXYTE', 'B004TS2B4W'], 'buy_after_viewing': ['B00CS6P31U', 'B005LSCQ4Y', 'B0051EZX8Y', 'B006CRC98G']}, 'categories': [['Books', \"Children's Books\", 'Fairy Tales, Folk Tales & Myths', 'Anthologies'], ['Books', 'Literature & Fiction'], ['Kindle Store', 'Kindle eBooks', \"Children's eBooks\", 'Fairy Tales, Folk Tales & Myths', 'Anthologies'], ['Kindle Store', 'Kindle eBooks', \"Children's eBooks\", 'Fairy Tales, Folk Tales & Myths', 'Collections'], ['Kindle Store', 'Kindle eBooks', 'Literature & Fiction', 'Mythology & Folk Tales'], ['Kindle Store', 'Kindle eBooks', 'Science Fiction & Fantasy', 'Fantasy', 'Fairy Tales']]}\n",
    "\n",
    "\n",
    "    {'asin': '0554319187', 'title': \"Grimm's Fairy Stories\", 'price': 0.99, 'imUrl': 'http://ecx.images-amazon.com/images/I/41O2olixwXL.jpg', 'related': {'also_viewed': ['1607103133', '0394709306', '1937994317'], 'buy_after_viewing': ['1607103133', '0394709306', '0393088863', '0385189508']}, 'salesRank': {'Books': 2586251}, 'categories': [['Books']]}\n",
    "\n",
    "As we can see here, the only entry that is the same is the price, and it's dangerous to merge on the price as ebooks are often less expensive than the book version for the same content.\n",
    "\n",
    "- we find another service that can give us the title for a given asin :\n",
    "\n",
    "This is the option that we finally chose. The website http://asindb.com/ does exactly that. For this website, there is no bot detection as Amazon does. We can't retrieve the price, the category and the number of pages, but at least we can get the title. We can see the result below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  asin notfound\n",
      "B000FC26RI  B000FC26RI        1\n",
      "B000JMKU0Y  B000JMKU0Y        1\n"
     ]
    }
   ],
   "source": [
    "if ASINDB_GET_TITLE:\n",
    "    \n",
    "    LIMIT = 20\n",
    "    \n",
    "    prefix_asindb = 'http://asindb.com/USA/ASIN/'\n",
    "\n",
    "    dataframe = pd.DataFrame(columns=[['asin', 'title']])\n",
    "    notdefined = pd.DataFrame(columns=[['asin','notfound']])\n",
    "    dataframe.to_csv(asindb_ebooks)\n",
    "\n",
    "    for i, asin in enumerate(ebooks_asin_unique[:LIMIT]):\n",
    "        r = requests.get(prefix_asindb + asin, headers={'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:23.0) Gecko/20100101 Firefox/23.0'})\n",
    "        page_body = r.text\n",
    "        soup = BeautifulSoup(page_body, 'html.parser')\n",
    "\n",
    "        if i%10 == 0:\n",
    "            dataframe.to_csv(asindb_ebooks, header=False,mode='a')\n",
    "            dataframe = pd.DataFrame(columns=[['asin', 'title']])\n",
    "\n",
    "        notfound = soup.find_all('h6', text = 'No item found!!!')\n",
    "        if(len(notfound) > 0):\n",
    "            notdefined.loc[asin] = (asin,1)\n",
    "        else:\n",
    "            title = soup.find_all('th', text='Title')\n",
    "            if(len(title) > 0 and len(title[0].parent.findChildren()) >= 2):\n",
    "                dataframe.loc[asin] = (asin, title[0].parent.findChildren()[1].text)\n",
    "            else:\n",
    "                print('alerte :', asin)\n",
    "\n",
    "        waiting = np.random.rand()\n",
    "        time.sleep(waiting+1)\n",
    "\n",
    "    dataframe.to_csv(asindb_ebooks, header=False,mode='a')\n",
    "    dataframe = pd.DataFrame(columns=[['asin', 'title']])\n",
    "    \n",
    "    print(notdefined.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right above is the undefined entries dataframe (see below for more explanation).\n",
    "\n",
    "We can see below what kind of output it gives to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000FA64PA</td>\n",
       "      <td>B000FA64PA</td>\n",
       "      <td>Saboteur: Star Wars Legends (Darth Maul) (Shor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000FA64PK</td>\n",
       "      <td>B000FA64PK</td>\n",
       "      <td>Recovery: Star Wars Legends (The New Jedi Orde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        asin                                              title\n",
       "0  B000FA64PA  B000FA64PA  Saboteur: Star Wars Legends (Darth Maul) (Shor...\n",
       "1  B000FA64PK  B000FA64PK  Recovery: Star Wars Legends (The New Jedi Orde..."
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_csv(asindb_ebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2741"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_csv(asindb_ebooks, None).shape[0] # number of titles retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solution is of course not the best one : the asindb website does not contain everything. We have managed to retrieve 2741 titles over 4000 asins by using this technique, but we have no problem with the Amazon bot detection (and possible ban). We can see which entries were not retrieved by printing the notdefined dataframe.\n",
    "\n",
    "Of course, tu retrieve the 2741 entries, we set the LIMIT constant in the code to be 4000.\n",
    "\n",
    "We thus continue our analysis by using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kindle = pd.read_json(kindle_5core, lines=True)\n",
    "metadata = pd.read_csv(books_metadata_path)\n",
    "cross = pd.read_csv(asindb_ebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0001048791</td>\n",
       "      <td>{'Books': 6334800}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Crucible: Performed by Stuart Pankin, Jero...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0001048775</td>\n",
       "      <td>{'Books': 13243226}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Measure for Measure: Complete &amp;amp; Unabridged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0001048236</td>\n",
       "      <td>{'Books': 8973864}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Sherlock Holmes Audio Collection</td>\n",
       "      <td>9.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0000401048</td>\n",
       "      <td>{'Books': 6448843}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The rogue of publishers' row;: Confessions of ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001019880</td>\n",
       "      <td>{'Books': 9589258}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Classic Soul Winner's New Testament Bible</td>\n",
       "      <td>5.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        asin            salesRank   categories  \\\n",
       "0           0  0001048791   {'Books': 6334800}  [['Books']]   \n",
       "1           1  0001048775  {'Books': 13243226}  [['Books']]   \n",
       "2           2  0001048236   {'Books': 8973864}  [['Books']]   \n",
       "3           3  0000401048   {'Books': 6448843}  [['Books']]   \n",
       "4           4  0001019880   {'Books': 9589258}  [['Books']]   \n",
       "\n",
       "                                               title  price  \n",
       "0  The Crucible: Performed by Stuart Pankin, Jero...    NaN  \n",
       "1     Measure for Measure: Complete &amp; Unabridged    NaN  \n",
       "2               The Sherlock Holmes Audio Collection   9.26  \n",
       "3  The rogue of publishers' row;: Confessions of ...    NaN  \n",
       "4          Classic Soul Winner's New Testament Bible   5.39  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kindle = kindle.set_index('asin')\n",
    "\n",
    "merged_ebooks = pd.merge(kindle, metadata, on='asin')\n",
    "merged_asins = pd.merge(metadata, cross, on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_matched(list_asins, in_path, out_path):\n",
    "    pd.DataFrame(columns=[['asin','overall', 'summary', 'reviewerID', 'helpful','reviewText', 'reviewerName']]).to_csv(out_path)\n",
    "\n",
    "    for chunck in pd.read_json(in_path, lines=True, chunksize=50000):\n",
    "        filtered = chunck[chunck['asin'].isin(list_asins)].dropna(how='all')\n",
    "        if len(filtered) > 0:\n",
    "            filtered[['asin','overall', 'summary', 'reviewerID', 'helpful','reviewText', 'reviewerName']].to_csv(out_path,header=False, mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_matched(merged_asins['asin_x'].values, books_path, matched_books_path)\n",
    "find_matched(merged_asins['asin_y'].values, kindle_5core, matched_ebooks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_helpful(x):\n",
    "    x = literal_eval(x)\n",
    "    voters = int(x[0]) + int(x[1])\n",
    "    return 0.5 if voters == 0 else int(x[0])/voters\n",
    "\n",
    "def weighted_score(data):\n",
    "    \n",
    "    data['weighted_help'] = (data.helpful.astype(list)).apply(weighted_helpful)\n",
    "    \n",
    "    data['weighted_overall'] = data['weighted_help'] * data['overall']\n",
    "    weighted_score = data.groupby(data.index).sum()\n",
    "    weighted_score['score'] = weighted_score['weighted_overall']/weighted_score['weighted_help']\n",
    "    \n",
    "    return weighted_score['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_scores(data):\n",
    "    data['weighted_help'] = (data['helpful'].astype(list)).apply(weighted_helpful)\n",
    "    \n",
    "    func = lambda x: sid.polarity_scores(x)['compound']\n",
    "    \n",
    "    data['sentiment'] = data['reviewText'].apply(func)\n",
    "    data['weighted_sentiment'] = data['weighted_help'] * data['sentiment']\n",
    "    data['weighted_overall'] = data['weighted_help'] * data['overall']\n",
    "    weighted_score = data.groupby(data['asin']).sum()\n",
    "    weighted_score['sentiment score'] = weighted_score['weighted_sentiment']/weighted_score['weighted_help']\n",
    "    weighted_score['overall score'] = weighted_score['weighted_overall']/weighted_score['weighted_help']\n",
    "    \n",
    "    return weighted_score[['sentiment score', 'overall score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matched_ebooks= pd.read_csv(matched_ebooks_path)\n",
    "matched_books = pd.read_csv(matched_books_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weighted_scores_books = weighted_scores(matched_books)\n",
    "weighted_scores_ebooks = weighted_scores(matched_ebooks)\n",
    "\n",
    "weighted_scores_books.to_csv(weighted_scores_books_path)\n",
    "weighted_scores_ebooks.to_csv(weighted_scores_ebooks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_with_books = pd.merge(merged_asins, weighted_scores_books, left_on='asin_x', right_index=True)\n",
    "merged_with_all = pd.merge(merged_with_books, weighted_scores_ebooks, left_on='asin_y', right_index=True, suffixes=[' book', ' ebook'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>asin_x</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>asin_y</th>\n",
       "      <th>sentiment score book</th>\n",
       "      <th>overall score book</th>\n",
       "      <th>sentiment score ebook</th>\n",
       "      <th>overall score ebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1380542</td>\n",
       "      <td>1579660584</td>\n",
       "      <td>{'Books': 2486827}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Space Between</td>\n",
       "      <td>20.08</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.688440</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1448217</td>\n",
       "      <td>1595143394</td>\n",
       "      <td>{'Books': 141638}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Space Between</td>\n",
       "      <td>7.13</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>B002DYJ7DM</td>\n",
       "      <td>0.784577</td>\n",
       "      <td>4.221992</td>\n",
       "      <td>0.688440</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1200133</td>\n",
       "      <td>1463597029</td>\n",
       "      <td>{'Books': 4801158}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Epiphany</td>\n",
       "      <td>2.99</td>\n",
       "      <td>B00480OQS0</td>\n",
       "      <td>B00480OQS0</td>\n",
       "      <td>0.802369</td>\n",
       "      <td>4.564737</td>\n",
       "      <td>-0.057837</td>\n",
       "      <td>4.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1258058</td>\n",
       "      <td>1484967887</td>\n",
       "      <td>{'Books': 3543419}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Epiphany</td>\n",
       "      <td>3.99</td>\n",
       "      <td>B00480OQS0</td>\n",
       "      <td>B00480OQS0</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>4.524272</td>\n",
       "      <td>-0.057837</td>\n",
       "      <td>4.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3606</td>\n",
       "      <td>0007269854</td>\n",
       "      <td>{'Books': 2527081}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Ice Princess</td>\n",
       "      <td>7.59</td>\n",
       "      <td>B003ZUY19I</td>\n",
       "      <td>B003ZUY19I</td>\n",
       "      <td>0.451335</td>\n",
       "      <td>3.587818</td>\n",
       "      <td>0.835556</td>\n",
       "      <td>4.325581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1014015</td>\n",
       "      <td>0987930044</td>\n",
       "      <td>{'Books': 9330490}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>New Beginnings</td>\n",
       "      <td>2.99</td>\n",
       "      <td>B003CT32PQ</td>\n",
       "      <td>B003CT32PQ</td>\n",
       "      <td>0.912843</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>0.863943</td>\n",
       "      <td>4.352699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1768373</td>\n",
       "      <td>9769528706</td>\n",
       "      <td>{'Books': 2614811}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>New Beginnings</td>\n",
       "      <td>2.99</td>\n",
       "      <td>B003CT32PQ</td>\n",
       "      <td>B003CT32PQ</td>\n",
       "      <td>0.801781</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>0.863943</td>\n",
       "      <td>4.352699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4298</td>\n",
       "      <td>0007492316</td>\n",
       "      <td>{'Books': 3117732}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Sacrifice</td>\n",
       "      <td>3.79</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>0.646450</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.399021</td>\n",
       "      <td>4.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>161650</td>\n",
       "      <td>0312381867</td>\n",
       "      <td>{'Books': 153575}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Sacrifice</td>\n",
       "      <td>2.99</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>0.277431</td>\n",
       "      <td>3.996652</td>\n",
       "      <td>0.399021</td>\n",
       "      <td>4.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>460547</td>\n",
       "      <td>0679764100</td>\n",
       "      <td>{'Books': 458795}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Sacrifice</td>\n",
       "      <td>7.99</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>-0.215695</td>\n",
       "      <td>4.509804</td>\n",
       "      <td>0.399021</td>\n",
       "      <td>4.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>756124</td>\n",
       "      <td>0843960191</td>\n",
       "      <td>{'Books': 670947}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Sacrifice</td>\n",
       "      <td>3.99</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>0.095610</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>0.399021</td>\n",
       "      <td>4.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>999650</td>\n",
       "      <td>0983911800</td>\n",
       "      <td>{'Books': 1830668}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Sacrifice</td>\n",
       "      <td>3.99</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>0.491700</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>0.399021</td>\n",
       "      <td>4.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1016237</td>\n",
       "      <td>0988633442</td>\n",
       "      <td>{'Books': 3250210}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Sacrifice</td>\n",
       "      <td>2.99</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>0.782640</td>\n",
       "      <td>4.880000</td>\n",
       "      <td>0.399021</td>\n",
       "      <td>4.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1152668</td>\n",
       "      <td>1441514007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Sacrifice</td>\n",
       "      <td>1.99</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>0.774908</td>\n",
       "      <td>4.480748</td>\n",
       "      <td>0.399021</td>\n",
       "      <td>4.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1700081</td>\n",
       "      <td>1937593169</td>\n",
       "      <td>{'Books': 3226816}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Sacrifice</td>\n",
       "      <td>3.99</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>B004GNFWZ0</td>\n",
       "      <td>0.648526</td>\n",
       "      <td>4.225806</td>\n",
       "      <td>0.399021</td>\n",
       "      <td>4.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>19759</td>\n",
       "      <td>006087290X</td>\n",
       "      <td>{'Books': 391768}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Keeper</td>\n",
       "      <td>5.98</td>\n",
       "      <td>B003YJEKVY</td>\n",
       "      <td>B003YJEKVY</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>3.481274</td>\n",
       "      <td>0.957958</td>\n",
       "      <td>4.248927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>30839</td>\n",
       "      <td>0062219480</td>\n",
       "      <td>{'Books': 1278340}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Keeper</td>\n",
       "      <td>8.00</td>\n",
       "      <td>B003YJEKVY</td>\n",
       "      <td>B003YJEKVY</td>\n",
       "      <td>-0.096044</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>0.957958</td>\n",
       "      <td>4.248927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1514192</td>\n",
       "      <td>1613332645</td>\n",
       "      <td>{'Books': 7106592}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Keeper</td>\n",
       "      <td>2.99</td>\n",
       "      <td>B003YJEKVY</td>\n",
       "      <td>B003YJEKVY</td>\n",
       "      <td>0.884173</td>\n",
       "      <td>4.205845</td>\n",
       "      <td>0.957958</td>\n",
       "      <td>4.248927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>16583</td>\n",
       "      <td>0060593652</td>\n",
       "      <td>{'Books': 1115438}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Behind Closed Doors</td>\n",
       "      <td>8.89</td>\n",
       "      <td>B00134D6RQ</td>\n",
       "      <td>B00134D6RQ</td>\n",
       "      <td>0.659772</td>\n",
       "      <td>3.907091</td>\n",
       "      <td>0.906355</td>\n",
       "      <td>4.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>167065</td>\n",
       "      <td>0312934866</td>\n",
       "      <td>{'Books': 1596490}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Behind Closed Doors</td>\n",
       "      <td>7.59</td>\n",
       "      <td>B00134D6RQ</td>\n",
       "      <td>B00134D6RQ</td>\n",
       "      <td>0.791592</td>\n",
       "      <td>4.134152</td>\n",
       "      <td>0.906355</td>\n",
       "      <td>4.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>417514</td>\n",
       "      <td>0615529240</td>\n",
       "      <td>{'Books': 10742162}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Behind Closed Doors</td>\n",
       "      <td>3.99</td>\n",
       "      <td>B00134D6RQ</td>\n",
       "      <td>B00134D6RQ</td>\n",
       "      <td>-0.619629</td>\n",
       "      <td>4.764706</td>\n",
       "      <td>0.906355</td>\n",
       "      <td>4.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1231081</td>\n",
       "      <td>1478316926</td>\n",
       "      <td>{'Books': 2056309}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Behind Closed Doors</td>\n",
       "      <td>2.99</td>\n",
       "      <td>B00134D6RQ</td>\n",
       "      <td>B00134D6RQ</td>\n",
       "      <td>0.797457</td>\n",
       "      <td>4.579336</td>\n",
       "      <td>0.906355</td>\n",
       "      <td>4.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1274717</td>\n",
       "      <td>1493771469</td>\n",
       "      <td>{'Books': 2973633}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Behind Closed Doors</td>\n",
       "      <td>2.99</td>\n",
       "      <td>B00134D6RQ</td>\n",
       "      <td>B00134D6RQ</td>\n",
       "      <td>0.662020</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.906355</td>\n",
       "      <td>4.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1511505</td>\n",
       "      <td>1612130917</td>\n",
       "      <td>{'Books': 3209247}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Behind Closed Doors</td>\n",
       "      <td>6.49</td>\n",
       "      <td>B00134D6RQ</td>\n",
       "      <td>B00134D6RQ</td>\n",
       "      <td>0.802805</td>\n",
       "      <td>4.380952</td>\n",
       "      <td>0.906355</td>\n",
       "      <td>4.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1730045</td>\n",
       "      <td>3952397008</td>\n",
       "      <td>{'Books': 5225365}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Behind Closed Doors</td>\n",
       "      <td>3.99</td>\n",
       "      <td>B00134D6RQ</td>\n",
       "      <td>B00134D6RQ</td>\n",
       "      <td>0.025546</td>\n",
       "      <td>4.307692</td>\n",
       "      <td>0.906355</td>\n",
       "      <td>4.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>16647</td>\n",
       "      <td>0060595620</td>\n",
       "      <td>{'Books': 2956119}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>The Sweetest Taboo</td>\n",
       "      <td>8.70</td>\n",
       "      <td>B00480P58K</td>\n",
       "      <td>B00480P58K</td>\n",
       "      <td>0.861742</td>\n",
       "      <td>3.576512</td>\n",
       "      <td>0.934593</td>\n",
       "      <td>4.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>939562</td>\n",
       "      <td>097144899X</td>\n",
       "      <td>{'Books': 1397304}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Choices</td>\n",
       "      <td>7.69</td>\n",
       "      <td>B003MAK67M</td>\n",
       "      <td>B003MAK67M</td>\n",
       "      <td>0.793289</td>\n",
       "      <td>4.577703</td>\n",
       "      <td>0.606700</td>\n",
       "      <td>4.655172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>974364</td>\n",
       "      <td>0979390508</td>\n",
       "      <td>{'Books': 1766495}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Choices</td>\n",
       "      <td>11.83</td>\n",
       "      <td>B003MAK67M</td>\n",
       "      <td>B003MAK67M</td>\n",
       "      <td>0.899662</td>\n",
       "      <td>4.307692</td>\n",
       "      <td>0.606700</td>\n",
       "      <td>4.655172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1298029</td>\n",
       "      <td>1555830617</td>\n",
       "      <td>{'Books': 2584706}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Choices</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B003MAK67M</td>\n",
       "      <td>B003MAK67M</td>\n",
       "      <td>0.798748</td>\n",
       "      <td>3.535961</td>\n",
       "      <td>0.606700</td>\n",
       "      <td>4.655172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1517899</td>\n",
       "      <td>1615668292</td>\n",
       "      <td>{'Books': 3178237}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Choices</td>\n",
       "      <td>9.89</td>\n",
       "      <td>B003MAK67M</td>\n",
       "      <td>B003MAK67M</td>\n",
       "      <td>0.953983</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>0.606700</td>\n",
       "      <td>4.655172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1531219</td>\n",
       "      <td>1623807204</td>\n",
       "      <td>{'Books': 1199314}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Choices</td>\n",
       "      <td>5.79</td>\n",
       "      <td>B003MAK67M</td>\n",
       "      <td>B003MAK67M</td>\n",
       "      <td>0.448329</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>0.606700</td>\n",
       "      <td>4.655172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>18791</td>\n",
       "      <td>0060798874</td>\n",
       "      <td>{'Books': 1307964}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>War and Peace</td>\n",
       "      <td>8.00</td>\n",
       "      <td>B003X4M9F4</td>\n",
       "      <td>B003X4M9F4</td>\n",
       "      <td>0.328877</td>\n",
       "      <td>2.879271</td>\n",
       "      <td>0.620473</td>\n",
       "      <td>4.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>142025</td>\n",
       "      <td>0307266931</td>\n",
       "      <td>{'Books': 255337}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>War and Peace</td>\n",
       "      <td>10.99</td>\n",
       "      <td>B003X4M9F4</td>\n",
       "      <td>B003X4M9F4</td>\n",
       "      <td>0.564577</td>\n",
       "      <td>4.304518</td>\n",
       "      <td>0.620473</td>\n",
       "      <td>4.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>527794</td>\n",
       "      <td>0743412753</td>\n",
       "      <td>{'Books': 2192378}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>No Way Out</td>\n",
       "      <td>7.59</td>\n",
       "      <td>B004BA52K8</td>\n",
       "      <td>B004BA52K8</td>\n",
       "      <td>0.610387</td>\n",
       "      <td>3.838508</td>\n",
       "      <td>0.816800</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>611716</td>\n",
       "      <td>0786020415</td>\n",
       "      <td>{'Books': 1122705}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>No Way Out</td>\n",
       "      <td>4.99</td>\n",
       "      <td>B004BA52K8</td>\n",
       "      <td>B004BA52K8</td>\n",
       "      <td>0.518650</td>\n",
       "      <td>4.242149</td>\n",
       "      <td>0.816800</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>18960</td>\n",
       "      <td>0060813032</td>\n",
       "      <td>{'Books': 1269204}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Dragons from the Sea (The Strongbow Saga, Book 2)</td>\n",
       "      <td>3.60</td>\n",
       "      <td>B0049H8X86</td>\n",
       "      <td>B0049H8X86</td>\n",
       "      <td>0.478786</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>0.580280</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>19254</td>\n",
       "      <td>0060833149</td>\n",
       "      <td>{'Books': 766120}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Daddy's Girl</td>\n",
       "      <td>2.99</td>\n",
       "      <td>B001Q9EC3U</td>\n",
       "      <td>B001Q9EC3U</td>\n",
       "      <td>0.544872</td>\n",
       "      <td>3.907210</td>\n",
       "      <td>0.866635</td>\n",
       "      <td>4.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>265807</td>\n",
       "      <td>0425113671</td>\n",
       "      <td>{'Books': 5278074}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Daddy's Girl</td>\n",
       "      <td>8.49</td>\n",
       "      <td>B001Q9EC3U</td>\n",
       "      <td>B001Q9EC3U</td>\n",
       "      <td>-0.165653</td>\n",
       "      <td>4.797297</td>\n",
       "      <td>0.866635</td>\n",
       "      <td>4.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>618655</td>\n",
       "      <td>0786819863</td>\n",
       "      <td>{'Books': 264998}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Daddy's Girl</td>\n",
       "      <td>6.29</td>\n",
       "      <td>B001Q9EC3U</td>\n",
       "      <td>B001Q9EC3U</td>\n",
       "      <td>0.692759</td>\n",
       "      <td>3.760913</td>\n",
       "      <td>0.866635</td>\n",
       "      <td>4.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>966130</td>\n",
       "      <td>0977664902</td>\n",
       "      <td>{'Books': 8342822}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Daddy's Girl</td>\n",
       "      <td>13.85</td>\n",
       "      <td>B001Q9EC3U</td>\n",
       "      <td>B001Q9EC3U</td>\n",
       "      <td>0.111980</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.866635</td>\n",
       "      <td>4.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1205999</td>\n",
       "      <td>1466360267</td>\n",
       "      <td>{'Books': 2860599}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Daddy's Girl</td>\n",
       "      <td>1.99</td>\n",
       "      <td>B001Q9EC3U</td>\n",
       "      <td>B001Q9EC3U</td>\n",
       "      <td>0.100464</td>\n",
       "      <td>4.363636</td>\n",
       "      <td>0.866635</td>\n",
       "      <td>4.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1529938</td>\n",
       "      <td>162237150X</td>\n",
       "      <td>{'Books': 6402371}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Daddy's Girl</td>\n",
       "      <td>4.99</td>\n",
       "      <td>B001Q9EC3U</td>\n",
       "      <td>B001Q9EC3U</td>\n",
       "      <td>0.897144</td>\n",
       "      <td>4.777778</td>\n",
       "      <td>0.866635</td>\n",
       "      <td>4.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>23243</td>\n",
       "      <td>0061083275</td>\n",
       "      <td>{'Books': 1122570}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Second Chances</td>\n",
       "      <td>7.19</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>0.731523</td>\n",
       "      <td>4.472211</td>\n",
       "      <td>0.884804</td>\n",
       "      <td>4.220204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>296014</td>\n",
       "      <td>0451198212</td>\n",
       "      <td>{'Books': 1982799}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Second Chances</td>\n",
       "      <td>3.99</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>0.750818</td>\n",
       "      <td>3.945556</td>\n",
       "      <td>0.884804</td>\n",
       "      <td>4.220204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>900617</td>\n",
       "      <td>095641012X</td>\n",
       "      <td>{'Books': 5196488}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Second Chances</td>\n",
       "      <td>2.99</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>0.484299</td>\n",
       "      <td>4.413793</td>\n",
       "      <td>0.884804</td>\n",
       "      <td>4.220204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>945587</td>\n",
       "      <td>097260586X</td>\n",
       "      <td>{'Books': 8014907}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Second Chances</td>\n",
       "      <td>2.99</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>0.412395</td>\n",
       "      <td>4.746424</td>\n",
       "      <td>0.884804</td>\n",
       "      <td>4.220204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1241281</td>\n",
       "      <td>1480805629</td>\n",
       "      <td>{'Books': 5315091}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Second Chances</td>\n",
       "      <td>3.49</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>0.960392</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>0.884804</td>\n",
       "      <td>4.220204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1247765</td>\n",
       "      <td>1482068346</td>\n",
       "      <td>{'Books': 1418907}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Second Chances</td>\n",
       "      <td>3.99</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>0.713268</td>\n",
       "      <td>4.290379</td>\n",
       "      <td>0.884804</td>\n",
       "      <td>4.220204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1256708</td>\n",
       "      <td>1484829026</td>\n",
       "      <td>{'Books': 424112}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Second Chances</td>\n",
       "      <td>3.99</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>0.828667</td>\n",
       "      <td>4.590709</td>\n",
       "      <td>0.884804</td>\n",
       "      <td>4.220204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1262193</td>\n",
       "      <td>149058241X</td>\n",
       "      <td>{'Books': 5104631}</td>\n",
       "      <td>[['Books']]</td>\n",
       "      <td>Second Chances</td>\n",
       "      <td>1.99</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>B004322F7W</td>\n",
       "      <td>0.701674</td>\n",
       "      <td>3.942857</td>\n",
       "      <td>0.884804</td>\n",
       "      <td>4.220204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0_x      asin_x            salesRank   categories  \\\n",
       "2         1380542  1579660584   {'Books': 2486827}  [['Books']]   \n",
       "4         1448217  1595143394    {'Books': 141638}  [['Books']]   \n",
       "13        1200133  1463597029   {'Books': 4801158}  [['Books']]   \n",
       "14        1258058  1484967887   {'Books': 3543419}  [['Books']]   \n",
       "20           3606  0007269854   {'Books': 2527081}  [['Books']]   \n",
       "24        1014015  0987930044   {'Books': 9330490}  [['Books']]   \n",
       "31        1768373  9769528706   {'Books': 2614811}  [['Books']]   \n",
       "32           4298  0007492316   {'Books': 3117732}  [['Books']]   \n",
       "33         161650  0312381867    {'Books': 153575}  [['Books']]   \n",
       "38         460547  0679764100    {'Books': 458795}  [['Books']]   \n",
       "42         756124  0843960191    {'Books': 670947}  [['Books']]   \n",
       "46         999650  0983911800   {'Books': 1830668}  [['Books']]   \n",
       "47        1016237  0988633442   {'Books': 3250210}  [['Books']]   \n",
       "48        1152668  1441514007                  NaN  [['Books']]   \n",
       "51        1700081  1937593169   {'Books': 3226816}  [['Books']]   \n",
       "53          19759  006087290X    {'Books': 391768}  [['Books']]   \n",
       "54          30839  0062219480   {'Books': 1278340}  [['Books']]   \n",
       "61        1514192  1613332645   {'Books': 7106592}  [['Books']]   \n",
       "64          16583  0060593652   {'Books': 1115438}  [['Books']]   \n",
       "65         167065  0312934866   {'Books': 1596490}  [['Books']]   \n",
       "67         417514  0615529240  {'Books': 10742162}  [['Books']]   \n",
       "77        1231081  1478316926   {'Books': 2056309}  [['Books']]   \n",
       "80        1274717  1493771469   {'Books': 2973633}  [['Books']]   \n",
       "85        1511505  1612130917   {'Books': 3209247}  [['Books']]   \n",
       "87        1730045  3952397008   {'Books': 5225365}  [['Books']]   \n",
       "88          16647  0060595620   {'Books': 2956119}  [['Books']]   \n",
       "95         939562  097144899X   {'Books': 1397304}  [['Books']]   \n",
       "96         974364  0979390508   {'Books': 1766495}  [['Books']]   \n",
       "111       1298029  1555830617   {'Books': 2584706}  [['Books']]   \n",
       "115       1517899  1615668292   {'Books': 3178237}  [['Books']]   \n",
       "116       1531219  1623807204   {'Books': 1199314}  [['Books']]   \n",
       "120         18791  0060798874   {'Books': 1307964}  [['Books']]   \n",
       "122        142025  0307266931    {'Books': 255337}  [['Books']]   \n",
       "135        527794  0743412753   {'Books': 2192378}  [['Books']]   \n",
       "136        611716  0786020415   {'Books': 1122705}  [['Books']]   \n",
       "138         18960  0060813032   {'Books': 1269204}  [['Books']]   \n",
       "139         19254  0060833149    {'Books': 766120}  [['Books']]   \n",
       "140        265807  0425113671   {'Books': 5278074}  [['Books']]   \n",
       "142        618655  0786819863    {'Books': 264998}  [['Books']]   \n",
       "144        966130  0977664902   {'Books': 8342822}  [['Books']]   \n",
       "146       1205999  1466360267   {'Books': 2860599}  [['Books']]   \n",
       "147       1529938  162237150X   {'Books': 6402371}  [['Books']]   \n",
       "148         23243  0061083275   {'Books': 1122570}  [['Books']]   \n",
       "150        296014  0451198212   {'Books': 1982799}  [['Books']]   \n",
       "162        900617  095641012X   {'Books': 5196488}  [['Books']]   \n",
       "164        945587  097260586X   {'Books': 8014907}  [['Books']]   \n",
       "184       1241281  1480805629   {'Books': 5315091}  [['Books']]   \n",
       "188       1247765  1482068346   {'Books': 1418907}  [['Books']]   \n",
       "190       1256708  1484829026    {'Books': 424112}  [['Books']]   \n",
       "192       1262193  149058241X   {'Books': 5104631}  [['Books']]   \n",
       "\n",
       "                                                 title  price Unnamed: 0_y  \\\n",
       "2                                    The Space Between  20.08   B002DYJ7DM   \n",
       "4                                    The Space Between   7.13   B002DYJ7DM   \n",
       "13                                            Epiphany   2.99   B00480OQS0   \n",
       "14                                            Epiphany   3.99   B00480OQS0   \n",
       "20                                    The Ice Princess   7.59   B003ZUY19I   \n",
       "24                                      New Beginnings   2.99   B003CT32PQ   \n",
       "31                                      New Beginnings   2.99   B003CT32PQ   \n",
       "32                                           Sacrifice   3.79   B004GNFWZ0   \n",
       "33                                           Sacrifice   2.99   B004GNFWZ0   \n",
       "38                                           Sacrifice   7.99   B004GNFWZ0   \n",
       "42                                           Sacrifice   3.99   B004GNFWZ0   \n",
       "46                                           Sacrifice   3.99   B004GNFWZ0   \n",
       "47                                           Sacrifice   2.99   B004GNFWZ0   \n",
       "48                                           Sacrifice   1.99   B004GNFWZ0   \n",
       "51                                           Sacrifice   3.99   B004GNFWZ0   \n",
       "53                                          The Keeper   5.98   B003YJEKVY   \n",
       "54                                          The Keeper   8.00   B003YJEKVY   \n",
       "61                                          The Keeper   2.99   B003YJEKVY   \n",
       "64                                 Behind Closed Doors   8.89   B00134D6RQ   \n",
       "65                                 Behind Closed Doors   7.59   B00134D6RQ   \n",
       "67                                 Behind Closed Doors   3.99   B00134D6RQ   \n",
       "77                                 Behind Closed Doors   2.99   B00134D6RQ   \n",
       "80                                 Behind Closed Doors   2.99   B00134D6RQ   \n",
       "85                                 Behind Closed Doors   6.49   B00134D6RQ   \n",
       "87                                 Behind Closed Doors   3.99   B00134D6RQ   \n",
       "88                                  The Sweetest Taboo   8.70   B00480P58K   \n",
       "95                                             Choices   7.69   B003MAK67M   \n",
       "96                                             Choices  11.83   B003MAK67M   \n",
       "111                                            Choices    NaN   B003MAK67M   \n",
       "115                                            Choices   9.89   B003MAK67M   \n",
       "116                                            Choices   5.79   B003MAK67M   \n",
       "120                                      War and Peace   8.00   B003X4M9F4   \n",
       "122                                      War and Peace  10.99   B003X4M9F4   \n",
       "135                                         No Way Out   7.59   B004BA52K8   \n",
       "136                                         No Way Out   4.99   B004BA52K8   \n",
       "138  Dragons from the Sea (The Strongbow Saga, Book 2)   3.60   B0049H8X86   \n",
       "139                                       Daddy's Girl   2.99   B001Q9EC3U   \n",
       "140                                       Daddy's Girl   8.49   B001Q9EC3U   \n",
       "142                                       Daddy's Girl   6.29   B001Q9EC3U   \n",
       "144                                       Daddy's Girl  13.85   B001Q9EC3U   \n",
       "146                                       Daddy's Girl   1.99   B001Q9EC3U   \n",
       "147                                       Daddy's Girl   4.99   B001Q9EC3U   \n",
       "148                                     Second Chances   7.19   B004322F7W   \n",
       "150                                     Second Chances   3.99   B004322F7W   \n",
       "162                                     Second Chances   2.99   B004322F7W   \n",
       "164                                     Second Chances   2.99   B004322F7W   \n",
       "184                                     Second Chances   3.49   B004322F7W   \n",
       "188                                     Second Chances   3.99   B004322F7W   \n",
       "190                                     Second Chances   3.99   B004322F7W   \n",
       "192                                     Second Chances   1.99   B004322F7W   \n",
       "\n",
       "         asin_y  sentiment score book  overall score book  \\\n",
       "2    B002DYJ7DM              0.132400            5.000000   \n",
       "4    B002DYJ7DM              0.784577            4.221992   \n",
       "13   B00480OQS0              0.802369            4.564737   \n",
       "14   B00480OQS0              0.680000            4.524272   \n",
       "20   B003ZUY19I              0.451335            3.587818   \n",
       "24   B003CT32PQ              0.912843            4.347826   \n",
       "31   B003CT32PQ              0.801781            4.428571   \n",
       "32   B004GNFWZ0              0.646450            4.600000   \n",
       "33   B004GNFWZ0              0.277431            3.996652   \n",
       "38   B004GNFWZ0             -0.215695            4.509804   \n",
       "42   B004GNFWZ0              0.095610            4.142857   \n",
       "46   B004GNFWZ0              0.491700            4.428571   \n",
       "47   B004GNFWZ0              0.782640            4.880000   \n",
       "48   B004GNFWZ0              0.774908            4.480748   \n",
       "51   B004GNFWZ0              0.648526            4.225806   \n",
       "53   B003YJEKVY              0.081301            3.481274   \n",
       "54   B003YJEKVY             -0.096044            3.111111   \n",
       "61   B003YJEKVY              0.884173            4.205845   \n",
       "64   B00134D6RQ              0.659772            3.907091   \n",
       "65   B00134D6RQ              0.791592            4.134152   \n",
       "67   B00134D6RQ             -0.619629            4.764706   \n",
       "77   B00134D6RQ              0.797457            4.579336   \n",
       "80   B00134D6RQ              0.662020            4.200000   \n",
       "85   B00134D6RQ              0.802805            4.380952   \n",
       "87   B00134D6RQ              0.025546            4.307692   \n",
       "88   B00480P58K              0.861742            3.576512   \n",
       "95   B003MAK67M              0.793289            4.577703   \n",
       "96   B003MAK67M              0.899662            4.307692   \n",
       "111  B003MAK67M              0.798748            3.535961   \n",
       "115  B003MAK67M              0.953983            4.833333   \n",
       "116  B003MAK67M              0.448329            4.285714   \n",
       "120  B003X4M9F4              0.328877            2.879271   \n",
       "122  B003X4M9F4              0.564577            4.304518   \n",
       "135  B004BA52K8              0.610387            3.838508   \n",
       "136  B004BA52K8              0.518650            4.242149   \n",
       "138  B0049H8X86              0.478786            4.714286   \n",
       "139  B001Q9EC3U              0.544872            3.907210   \n",
       "140  B001Q9EC3U             -0.165653            4.797297   \n",
       "142  B001Q9EC3U              0.692759            3.760913   \n",
       "144  B001Q9EC3U              0.111980            4.400000   \n",
       "146  B001Q9EC3U              0.100464            4.363636   \n",
       "147  B001Q9EC3U              0.897144            4.777778   \n",
       "148  B004322F7W              0.731523            4.472211   \n",
       "150  B004322F7W              0.750818            3.945556   \n",
       "162  B004322F7W              0.484299            4.413793   \n",
       "164  B004322F7W              0.412395            4.746424   \n",
       "184  B004322F7W              0.960392            4.083333   \n",
       "188  B004322F7W              0.713268            4.290379   \n",
       "190  B004322F7W              0.828667            4.590709   \n",
       "192  B004322F7W              0.701674            3.942857   \n",
       "\n",
       "     sentiment score ebook  overall score ebook  \n",
       "2                 0.688440             3.800000  \n",
       "4                 0.688440             3.800000  \n",
       "13               -0.057837             4.125000  \n",
       "14               -0.057837             4.125000  \n",
       "20                0.835556             4.325581  \n",
       "24                0.863943             4.352699  \n",
       "31                0.863943             4.352699  \n",
       "32                0.399021             4.263158  \n",
       "33                0.399021             4.263158  \n",
       "38                0.399021             4.263158  \n",
       "42                0.399021             4.263158  \n",
       "46                0.399021             4.263158  \n",
       "47                0.399021             4.263158  \n",
       "48                0.399021             4.263158  \n",
       "51                0.399021             4.263158  \n",
       "53                0.957958             4.248927  \n",
       "54                0.957958             4.248927  \n",
       "61                0.957958             4.248927  \n",
       "64                0.906355             4.181818  \n",
       "65                0.906355             4.181818  \n",
       "67                0.906355             4.181818  \n",
       "77                0.906355             4.181818  \n",
       "80                0.906355             4.181818  \n",
       "85                0.906355             4.181818  \n",
       "87                0.906355             4.181818  \n",
       "88                0.934593             4.571429  \n",
       "95                0.606700             4.655172  \n",
       "96                0.606700             4.655172  \n",
       "111               0.606700             4.655172  \n",
       "115               0.606700             4.655172  \n",
       "116               0.606700             4.655172  \n",
       "120               0.620473             4.909091  \n",
       "122               0.620473             4.909091  \n",
       "135               0.816800             5.000000  \n",
       "136               0.816800             5.000000  \n",
       "138               0.580280             4.600000  \n",
       "139               0.866635             4.794118  \n",
       "140               0.866635             4.794118  \n",
       "142               0.866635             4.794118  \n",
       "144               0.866635             4.794118  \n",
       "146               0.866635             4.794118  \n",
       "147               0.866635             4.794118  \n",
       "148               0.884804             4.220204  \n",
       "150               0.884804             4.220204  \n",
       "162               0.884804             4.220204  \n",
       "164               0.884804             4.220204  \n",
       "184               0.884804             4.220204  \n",
       "188               0.884804             4.220204  \n",
       "190               0.884804             4.220204  \n",
       "192               0.884804             4.220204  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_with_all.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
